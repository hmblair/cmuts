{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#cmuts","title":"cmuts","text":"<p>Fast mutation counting and reactivity profiling for MaP-seq experiments.</p> <p></p>"},{"location":"#overview","title":"Overview","text":"<p><code>cmuts</code> is a high-performance program designed for analyzing MaP-seq (Mutational Profiling via sequencing) experiments. It provides comprehensive tools for counting mutations and computing reactivity profiles with exceptional speed and accuracy.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>:material-flash: Fast, compiled C++ code with native multithreading support</li> <li>:material-harddisk: Streamed IO and direct output to compressed HDF5 files  </li> <li>:material-dna: Advanced deletion handling including arbitrary-length ambiguous deletions with mutation-informed spreading</li> <li>:material-cog: Four independent processing steps for complete analysis workflow</li> </ul>"},{"location":"#workflow-components","title":"Workflow Components","text":"<p>cmuts performs analysis through four main components:</p> <ol> <li>Modification Counting - Identify and count mutations in aligned sequencing reads</li> <li>Normalization - Compute normalized reactivity profiles using <code>cmuts-normalize</code></li> <li>Tokenization - Convert reference sequences to numerical tokens (optional)</li> <li>Joint Analysis - Analyze co-occurring modifications across positions (optional)</li> </ol>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get up and running with cmuts in just a few commands:</p> <pre><code># Basic mutation counting\ncmuts -o output.h5 -f reference.fasta aligned_reads.bam\n\n# Recommended for standard MaP-seq analysis\ncmuts -o output.h5 -f reference.fasta aligned_reads.bam \\\n    --no-insertions \\\n    --filter-coverage\n\n# Parallel processing with MPI\nmpirun -np 8 cmuts -o output.h5 -f reference.fasta aligned_reads.bam\n</code></pre>"},{"location":"#what-you-need","title":"What You Need","text":"<p>To get started with cmuts, you'll need:</p> <ul> <li>Reference sequences in FASTA format</li> <li>Aligned reads in SAM/BAM/CRAM format</li> <li>Index files (<code>.bai</code> or <code>.crai</code>) - created automatically if missing</li> </ul> <p>File Preparation</p> <p>If your alignment file isn't sorted, cmuts will automatically call <code>samtools sort</code> to prepare it for analysis.</p>"},{"location":"#output-format","title":"Output Format","text":"<p>cmuts generates HDF5 files containing mutation count data with dimensions <code>n \u00d7 l \u00d7 4 \u00d7 7</code>, where:</p> <ul> <li><code>n</code> = number of reference sequences</li> <li><code>l</code> = maximum sequence length</li> <li><code>4</code> = original base types (A, C, G, T)</li> <li><code>7</code> = mutation types (A, C, G, T substitutions + insertions + deletions + matches)</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation Requirements - System requirements and dependencies</li> <li>Basic Installation - Step-by-step installation guide</li> <li>Usage Examples - Detailed usage scenarios and examples</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>:material-github: Issues: Report bugs or request features</li> <li>:material-file-document: Documentation: Complete guides and API reference</li> <li>:material-email: Contact: Reach out for questions or collaboration</li> </ul> <p>cmuts is designed for researchers working with MaP-seq data who need fast, accurate mutation analysis with minimal computational overhead.</p>"},{"location":"installation/installation/","title":"Installation","text":""},{"location":"installation/installation/#installation","title":"Installation","text":""},{"location":"installation/installation/#1-obtain-cmuts","title":"1. Obtain <code>cmuts</code>","text":"<p>Clone the <code>cmuts</code> repository with all submodules:</p> <pre><code>git clone --recurse-submodules https://github.com/hmblair/cmuts\ncd cmuts\n</code></pre>"},{"location":"installation/installation/#2-build-cmuts","title":"2. Build <code>cmuts</code>","text":"<p>The configuration script contains all required setup and build steps.</p> <pre><code>./configure\n</code></pre> <p>If building the multithreaded version, pass the <code>--mpi</code> flag to the script.</p> <pre><code>./configure --mpi\n</code></pre> <p>A debug build, which reduces optimization and enables various sanitizers, is also possible.</p> <pre><code>./configure --debug\n</code></pre> <p>Warning</p> <p>Building with <code>--mpi</code> or <code>--debug</code> after an existing build has already been performed will require deleting the <code>build</code> directory first.</p>"},{"location":"installation/installation/#3-modify-path","title":"3. Modify PATH","text":"<p>Afterwards, add the <code>cmuts</code> binary directory to your PATH:</p> Temporary (current session)Permanent (bash)Permanent (zsh) <pre><code>export PATH=\"$(pwd)/bin:$PATH\"\n</code></pre> <pre><code>echo 'export PATH=\"'$(pwd)'/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <pre><code>echo 'export PATH=\"'$(pwd)'/bin:$PATH\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"installation/installation/#updating","title":"Updating","text":"<p>To update to a newer version, from within the <code>cmuts</code> directory, run</p> <pre><code>git pull origin master\ngit submodule update --recursive\nrm -rf build\n./configure # OR ./configure --mpi\n</code></pre>"},{"location":"installation/org-notes/","title":"Organization-Specific Notes","text":"<p>The following is an incomplete list of various locations where <code>cmuts</code> has been run, and the specific requirements for each one.</p>"},{"location":"installation/org-notes/#stanford-sherlock-cluster","title":"Stanford Sherlock Cluster","text":"<p>Both building and running will require the following, which covers all dependencies.</p> <pre><code>ml load hdf5/1.14.4\nml load biology samtools/1.16.1\nml load cmake/3.31.4\n</code></pre>"},{"location":"installation/org-notes/#hhmi-janelia-cluster","title":"HHMI Janelia Cluster","text":"<p>Running will require the following two commands.</p> <pre><code>ml load samtools\nLD_LIBRARY_PATH=/misc/local/samtools-1.22.1/lib:$LD_LIBRARY_PATH\n</code></pre> <p>In addition, building <code>cmuts</code> will require</p> <pre><code>ml load cmake/4.0.2\nexport PKG_CONFIG_PATH=/misc/local/samtools-1.22.1/lib/pkgconfig:$PKG_CONFIG_PATH\n</code></pre>"},{"location":"installation/requirements/","title":"Requirements","text":""},{"location":"installation/requirements/#dependencies","title":"Dependencies","text":"<p>Installing and running the <code>cmuts</code> pipeline requires the following packages:</p> <ul> <li><code>python&gt;=3.10</code> with all packages in <code>requirements.txt</code></li> <li><code>cmake&gt;=3.29</code> with <code>pkg-config</code></li> <li><code>autoconf</code></li> <li><code>samtools</code> and <code>htslib</code></li> <li><code>hdf5</code></li> </ul> <p>The MPI build also requires</p> <ul> <li><code>openmpi</code></li> <li><code>hdf5-mpi</code></li> </ul> <p>The following should install all (save for <code>python</code> and its packages) on a personal device. For installation on a managed cluster, consult the respective guidelines.</p> Mac OSLinux <pre><code># Install brew from https://brew.sh\nbrew install cmake autoconf samtools\n# For non-MPI builds only:\nbrew install hdf5\n# For MPI builds only:\nbrew install openmpi hdf5-mpi\n</code></pre> <pre><code>\n</code></pre> <p>Verify Dependencies</p> <p>Run these commands to verify the dependencies are successfully installed: </p><pre><code>cmake --version\npkg-config --modversion hdf5\nautoreconf --version\nsamtools --version\nh5ls --version\n</code></pre> For MPI builds, also run: <pre><code>mpirun --version\n</code></pre><p></p>"},{"location":"installation/requirements/#environment-variables","title":"Environment Variables","text":""},{"location":"installation/requirements/#hdf5-configuration","title":"HDF5 Configuration","text":"<p>If <code>cmake</code> has trouble finding your HDF5 installation, you can set</p> <pre><code>export HDF5_DIR=/path/to/hdf5/installation\n</code></pre> <p>If installed via brew, the command <code>brew info hdf5</code> may be helpful for finding the desired path.</p>"},{"location":"usage/cmuts-align/","title":"cmuts align","text":""},{"location":"usage/cmuts-align/#purpose","title":"Purpose","text":"<p><code>cmuts align</code> is a simple wrapper script for performing trimming, demultiplexing, and alignment of one or more FASTQ files against a reference FASTA file, and sorting of the resulting SAM files. This is required if running <code>cmuts</code> directly from raw sequencing data.</p>"},{"location":"usage/cmuts-align/#usage","title":"Usage","text":""},{"location":"usage/cmuts-align/#alignment","title":"Alignment","text":"<p>By defaut, <code>cmuts align</code> will perform alignment only, which also includes building the <code>bowtie2</code> index files and sorting the output SAM files. The syntax is</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n</code></pre> <p>The sorted alignments will be in BAM format and can be found in the directory <code>$ALIGNMENTS</code>, with the same basename as the original FASTQ files.</p> <p>The default is for <code>cmuts align</code> to use <code>--end-to-end</code> alignment. To use <code>--local</code> alignment instead, simply pass the <code>--local</code> argument.</p>"},{"location":"usage/cmuts-align/#paired-end-alignment","title":"Paired-End Alignment","text":"<p>To specify mates for paired-end sequencing, pass the additional FASTQ files to the <code>--pairs</code> argument after the forward reads.</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq* \\\n  --pairs \"$PAIRS\"/*.fastq*\n</code></pre> <p>Warning</p> <p>The <code>--pairs</code> inputs must come after the forward reads, otherwise <code>cmuts align</code> will not be able to distinguish what you intend to be the mate.</p>"},{"location":"usage/cmuts-align/#demultiplexing","title":"Demultiplexing","text":"<p>Pre-alignment demultiplexing (via <code>ultraplex</code>) can be achieved by passing a CSV of barcodes to the <code>--barcodes</code> argument.</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --barcodes \"$BARCODES\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n</code></pre> <p>The sorted alignments will again be in BAM format under the directory <code>$ALIGNMENTS</code>. However, their names will be given by the respective barcode which they correspond to, not the name of the original FASTQ file.</p> <p>Warning</p> <p>If the barcodes are named in the CSV file, then the outputs will have those as names rather than the respective barcodes (see <code>ultraplex</code> documentation).</p>"},{"location":"usage/cmuts-align/#trimming","title":"Trimming","text":"<p>Pre-alignment trimming (via <code>cutadapt</code>) can be achieved by passing a sequence to either the <code>--trim-5</code> or <code>--trim-3</code> argument, depending on which side the adapter belongs to. Separate adapters can be passed for each.</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --trim-5 \"$TRIM5\" \\\n  --trim-3 \"$TRIM3\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n</code></pre> <p>Trimming does not change the format of the output.</p> <p>Warning</p> <p>If at least one of <code>--trim-5</code> and <code>--trim-3</code> are passed with <code>--barcodes</code> specified, the trimming will occur first.</p>"},{"location":"usage/cmuts-normalize/","title":"cmuts normalize","text":""},{"location":"usage/cmuts-normalize/#usage","title":"Usage","text":"<p>To run <code>cmuts normalize</code> requires an HDF5 file of modification counts generated by <code>cmuts core</code>. The basic syntax is </p><pre><code>cmuts normalize \\\n  -o $OUTPUT \\\n  --mod $MOD \\\n  --nomod $NOMOD \\\n  $FILE\n</code></pre> The <code>--mod</code> and <code>--nomod</code> flags specify the HDF5 datasets in which the treated and untreated modification counts are stored, respectively. The latter is optional.<p></p> <p>Tip</p> <p>More than one file can be passed to <code>cmuts normalize</code>. In such a case, the modification counts are summed across the files before normalization. This is useful in the case where the inputs to <code>cmuts core</code> were split across multiple files.</p>"},{"location":"usage/cmuts-normalize/#command-line-options","title":"Command Line Options","text":""},{"location":"usage/cmuts-normalize/#core-options","title":"Core Options","text":"<p><code>-o, --output</code> : Output HDF5 filename (required)</p> <p><code>--mod</code> : Name of the dataset containing treated modification counts (required)</p> <p><code>--nomod</code> : Name of the dataset containing untreated modification counts</p>"},{"location":"usage/cmuts-normalize/#output-control","title":"Output Control","text":"<p><code>--overwrite</code> : Overwrite existing HDF5 file</p> <p><code>--group</code> : HDF5 group to place the output datasets in (none if not specified)</p>"},{"location":"usage/cmuts-normalize/#normalization-control","title":"Normalization Control","text":"<p><code>--raw</code> : Do not normalize the reactivity values</p> <p><code>--clip-low</code> : Clip negative reactivity values</p> <p><code>--clip-high</code> : Clip reactivity values above 1</p> <p><code>--blank-5p</code> : NaN out this many bases on the 5' end (default: 0)</p> <p><code>--blank-3p</code> : NaN out this many bases on the 3' end (default: 0)</p> <p><code>--blank-cutoff</code> : NaN out any positions with less than this many reads (default: 10)</p> <p><code>--norm-independent</code> : Normalize each profile separately, rather than using experiment-wide statistics </p>"},{"location":"usage/cmuts-normalize/#outputs","title":"Outputs","text":""},{"location":"usage/cmuts-normalize/#files","title":"Files","text":"<p>The output of <code>cmuts normalize</code> will be an HDF5 file with the following structure:</p> <pre><code>/\n\u251c\u2500\u2500 roi-mask\n\u251c\u2500\u2500 SNR\n\u251c\u2500\u2500 error\n\u251c\u2500\u2500 heatmap\n\u251c\u2500\u2500 norm\n\u251c\u2500\u2500 reactivity\n\u2514\u2500\u2500 reads\n</code></pre> <p>roi-mask (Region Of Interest): A boolean array indicating the region of the RNA which is of structural importance (i.e. all but the flanking sequences).</p> <p>SNR (Signal-To-Noise): An estimate of the average SNR, based on the computed error, for each reference.</p> <p>error: The standard error of the mean at each position.</p> <p>heatmap: The prevalence of each mutation, insertion, and deletion type throughout the entire library.</p> <p>norm: The normalization value used. It will be a scalar unless <code>--norm-independent</code> is passed, in which case each reference has its own norm value.</p> <p>reactivity: The reactivity profiles.</p> <p>reads: The number of reads used to compute each reactivity profile.</p> <p>Warning</p> <p>If a value was passed to <code>--group</code>, then the above will be contained in an HDF5 group with that name.</p>"},{"location":"usage/cmuts-normalize/#figures","title":"Figures","text":""},{"location":"usage/cmuts-visualize/","title":"cmuts visualize","text":""},{"location":"usage/cmuts-visualize/#purpose","title":"Purpose","text":"<p><code>cmuts visualize</code> may be used to overlay a reactivity profile generated via <code>cmuts</code> onto a 3D RNA structure.</p>"},{"location":"usage/cmuts-visualize/#usage","title":"Usage","text":"<p>The general syntax is </p><pre><code>cmuts visualize \\\n  --file \"$PROFILES\" \\\n  --dataset \"$NAME\" \\\n  --fasta \"$FASTA\" \\\n  --cif \"$CIF\"\n</code></pre> and an example can be found under <code>./examples/visualize</code>.<p></p> <p>The FASTA file is necessary to perform alignment of the sequence which was probed against the sequence of the 3D structure, which may be different e.g. due to flanking sequences.</p>"},{"location":"usage/cmuts-visualize/#command-line-options","title":"Command Line Options","text":""},{"location":"usage/cmuts-visualize/#core-options","title":"Core Options","text":"<p><code>--file</code> : Path to the HDF5 file containing the reactivity data</p> <p><code>--dataset</code> : Reactivity dataset name in the HDF5 file</p> <p><code>--fasta</code> : Path to .fasta file of the library which was chemically probed</p> <p><code>--cif</code> : Path to the .cif structure file (.pdb also works)</p> <p><code>--bin</code> : Path to the ChimeraX executable (default: ChimeraX)</p>"},{"location":"usage/cmuts-visualize/#selection-options","title":"Selection Options","text":"<p><code>--index</code> : Index of the sequence in the FASTA and the reactivity in the HDF5 file (default: 0)</p> <p><code>--chain</code> : Color this chain of the structure (default: ALL)</p> <p><code>--trim-5p</code> : Trim this many bases from the 5' end of the reactivity data (default: 0)</p> <p><code>--trim-3p</code> : Trim this many bases from the 3' end of the reactivity data (default: 0)</p>"},{"location":"usage/cmuts-visualize/#output-options","title":"Output Options","text":"<p><code>--color</code> : The ChimeraX color to use for highly reactive bases (default: indianred)</p>"},{"location":"usage/cmuts-visualize/#movies","title":"Movies","text":"<p>Once the structure is loaded into ChimeraX, you can record a movie of it rotating by running</p> <pre><code>movie record\nturn y 0.5 720\nmovie stop\nmovie encode PATH-TO-MOVIE\n</code></pre>"},{"location":"usage/cmuts/","title":"cmuts core","text":""},{"location":"usage/cmuts/#purpose","title":"Purpose","text":"<p><code>cmuts core</code> performs the main job of the <code>cmuts</code> pipeline, which is determining the location and type of mutations, insertions, and deletions in a collection of aligned reads.</p>"},{"location":"usage/cmuts/#usage","title":"Usage","text":"<p>All modes of <code>cmuts core</code> require two inputs to run:</p> <ol> <li>Reference sequences, stored in a FASTA file,</li> <li>Aligned reads, stored in one or more SAM/BAM/CRAM files</li> </ol> <p>The basic syntax is </p><pre><code>cmuts core \\\n  -o $OUTPUT \\\n  -f $FASTA \\\n  $FILES\n</code></pre><p></p> <p>Warning</p> <p>The alignments must be sorted before passing to <code>cmuts</code>. If you are generating them via <code>cmuts align</code>, then they will automatically be sorted for you.</p>"},{"location":"usage/cmuts/#modification-counting","title":"Modification Counting","text":"<p>Most uses of <code>cmuts core</code> (without any of the flags specified later) will output an HDF5 file with a dataset of shape \\(n \\times l \\times 4 \\times 7\\). The former two dimensions specify the reference sequence and residue respectively, and the latter two specify the type of modification seen in accordance with the following array:</p> <p></p> <p>The diagonal corresponds to matches, whereas the off-diagonal corresponds to mismatches. The final three columns correspond to deletions, insertions, and termination events respectively.</p> <p>The name of the dataset corresponds to the name of the input file. For example, the command</p> <pre><code>cmuts core \\\n  -o $OUTPUT \\\n  -f $FASTA \\\n  IN1.bam SUBDIR/IN2.bam\n</code></pre> <p>will create an HDF5 file <code>$OUTPUT</code> with the structure</p> <pre><code>/\n\u251c\u2500\u2500 IN1\n\u2514\u2500\u2500 SUBDIR\n    \u2514\u2500\u2500 IN2\n</code></pre> <p>and both <code>IN1</code> and <code>IN2</code> are datasets as described above. </p>"},{"location":"usage/cmuts/#pairwise-modification-counting","title":"Pairwise Modification Counting","text":"<p>The <code>--joint</code> flag instructs <code>cmuts core</code> to count pairs of mutations. The output is again an HDF5 file, with a dataset of shape \\(n \\times l \\times l \\times 2 \\times 2\\). The first dimension specifies the reference sequence, the next two specifies each pair of bases in that sequence, and the final two specify the four entries of the joint Bernoulli distribution:</p> \\[ \\begin{pmatrix} p_{00} &amp; p_{01} \\\\ p_{10} &amp; p_{11} \\end{pmatrix} \\]"},{"location":"usage/cmuts/#low-mem","title":"Low-Mem","text":"<p>The <code>--low-mem</code> flag instructs <code>cmuts core</code> to only store coverage and mutation counts, not mutation types. Correspondingly, the output dataset has shape \\(n \\times l \\times 2\\), with the final dimension specifying coverage and mutation counts respectively.</p>"},{"location":"usage/cmuts/#command-line-options","title":"Command Line Options","text":""},{"location":"usage/cmuts/#core-options","title":"Core Options","text":"<p><code>-o, --output</code> : Output HDF5 filename (required)</p> <p><code>-f, --fasta</code> : Reference FASTA file (required)</p> <p><code>-t, --threads</code> : The number of MPI processes to use (if built with MPI, default: 1)</p>"},{"location":"usage/cmuts/#output-control","title":"Output Control","text":"<p><code>--overwrite</code> : Overwrite existing HDF5 file</p> <p><code>--compression</code> : HDF5 compression level (0-9, default: 3)</p>"},{"location":"usage/cmuts/#analysis-modes","title":"Analysis Modes","text":"<p><code>--tokenize</code> : Tokenize reference sequences and store in <code>sequence</code> dataset</p> <p><code>--joint</code> : Compute joint distribution of mutations over all position pairs</p> <p><code>--low-mem</code> : Record only modification locations and coverage (not type), reducing memory usage by 2x+</p>"},{"location":"usage/cmuts/#quality-filtering","title":"Quality Filtering","text":"<p><code>--min-mapq</code> : Mapping quality threshold (default: 10)</p> <p><code>--min-phred</code> : PHRED score threshold (default: 10)</p> <p><code>--quality-window</code> : Quality check window size around each base (default: 2)</p> <p><code>--min-length</code> : Minimum alignment length (default: 2)</p> <p><code>--max-length</code> : Maximum alignment length (default: 1,024)</p> <p><code>--no-reverse</code> : Skip reverse-complemented reads</p> <p><code>--only-reverse</code> : Only use reverse-complemented reads</p>"},{"location":"usage/cmuts/#modification-detection","title":"Modification Detection","text":"<p><code>--max-indel-length</code> : Maximum indel length to consider (default: 10)</p> <p><code>--collapse</code> : Collapse modifications within this distance in a read (default: 2)</p> <p><code>--no-mismatches</code> : Exclude mismatches from modification counts</p> <p><code>--no-insertions</code> : Exclude insertions from modification counts</p> <p><code>--no-deletions</code> : Exclude deletions from modification counts</p>"},{"location":"usage/cmuts/#deletion-handling","title":"Deletion Handling","text":"<p><code>--deletion-gap</code> : The number of gaps to allow when detecting ambiguous deletions (default: 0)</p> <p><code>--uniform-spread</code> : Uniformly spread ambiguous deletions</p> <p><code>--no-spread</code> : Do not spread ambiguous deletions</p> <p><code>--disable-ambiguous</code> : Use alignment-provided deletions only</p> <p><code>--contiguous-ambiguous</code> : Allow only contiguous regions as ambiguous deletions</p>"},{"location":"usage/cmuts/#sampling-and-coverage","title":"Sampling and Coverage","text":"<p><code>--subsample</code> : Random read acceptance probability (default: 1.0)</p> <p><code>--no-match-filter</code> : Do not filter matches based on their PHRED base score (as in <code>rf-count</code>)</p> <p><code>--no-insertion-filter</code> : Do not filter insertions based on their PHRED base score (as in <code>rf-count</code>)</p> <p><code>--no-deletion-filter</code> : Do not filter deletions based on their PHRED base score (as in <code>rf-count</code>)</p>"},{"location":"usage/cmuts/#performance","title":"Performance","text":"<p><code>--chunk-size</code> : Internal buffer size per thread in references (default: 128)</p> <p><code>--print-every</code> : Progress update frequency in reads processed (default: 1,000)</p>"},{"location":"usage/examples/","title":"Examples","text":""},{"location":"usage/examples/#overview","title":"Overview","text":""},{"location":"usage/examples/#environment-setup","title":"Environment Setup","text":"<p>These variables will be used throughout the examples; feel free to set them to a value appropriate for your computer. The latter three specify the location of various intermediate files and outputs from the pipeline.</p> <pre><code>THREADS=8\nALIGNMENTS=\"examples/alignments\"\nCOUNTS=\"examples/counts.h5\"\nPROFILES=\"examples/profiles.h5\"\n</code></pre> <p>All files used in these examples can be found in the repo, under <code>examples</code>.</p>"},{"location":"usage/examples/#map-seq","title":"MaP-seq","text":"<pre><code>PARENT=\"examples/map-seq\"\n</code></pre> <p>A directory of FASTQ files and a reference FASTA file is required.</p> <pre><code>FASTQ=\"$PARENT/fastq\"\nFASTA=\"$PARENT/ref.fasta\"\n</code></pre> <p>In addition, <code>cmuts normalize</code> will need to know which datasets correspond to which condition. How this is specified depends on whether demultiplexing is performed or not.</p>"},{"location":"usage/examples/#without-demultiplexing","title":"Without Demultiplexing","text":"<p>The following arrays contain the basenames of the FASTQ files corresponding to each condition. A parallel array containing the name of each condition is necessary as well.</p> <pre><code>MODS=(\"bicine-2A3\", \"bicine-DMS\")\nNOMODS=(\"bicine-DMSO\", \"bicine-ETH\")\nNAMES=(\"2A3\", \"DMS\")\n</code></pre> <p><code>NOMODS</code> may be empty, in the case where background subtraction is not to be performed.</p> <p>One can run <code>cmuts align</code> directly on the FASTQ files and then pass the output to <code>cmuts core</code> to locate modifications.</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n\ncmuts core \\\n  -f \"$FASTA\" \\\n  -o \"$COUNTS\" \\\n  --no-insertions \\\n  \"$ALIGNMENTS\"/*\n</code></pre> <p>This will output a single HDF5 file, <code>$COUNTS</code>, which will contain one dataset for each input. The following statistics should also be printed:</p> <pre><code>        cmuts version 1.0.1\n      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        References:                    1\n        Reference length:            615\n        Aligned reads:             9,965\n        Unaligned reads:              35\n      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        File:                        4/4\n        Reads processed:          100.0%\n        Reads skipped:             18.3%\n        Time elapsed:           00:00:00\n      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre> <p>One can then loop over all input files, and pass the respective dataset to <code>cmuts normalize</code>.</p> <pre><code>for ((IX=0; IX&lt;${#MODS[@]}; IX++)); do\n  MOD_DS=\"$ALIGNMENTS\"/${MODS[IX]}\n  NOMOD_DS=\"$ALIGNMENTS\"/${NOMODS[IX]}\n  NAME=${NAMES[IX]}\n  cmuts normalize \\\n    -o \"$PROFILES\" \\\n    --mod \"$MOD_DS\" \\\n    --nomod \"$NOMOD_DS\" \\\n    --group \"$NAME\" \\\n    \"$COUNTS\"\ndone\n</code></pre> <p>The following will also be printed:</p> <pre><code>        cmuts-normalize version 1.0.1\n      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        Statistics for 2A3:\n        References:       1\n        Total reads:      3,088\n        Mean reads:       3088.00\n        Mean SNR:         1.28\n        Mean reactivity:  0.006\n        Median reads:     3,088\n        Median SNR:       1.28\n        Mean-to-Median:   1.00\n        Usable SNR:       1.00\n        Dropout Fraction: 0.00\n\n        cmuts-normalize version 1.0.1\n      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n        Statistics for DMS:\n        References:       1\n        Total reads:      3,716\n        Mean reads:       3716.00\n        Mean SNR:         2.51\n        Mean reactivity:  0.012\n        Median reads:     3,716\n        Median SNR:       2.51\n        Mean-to-Median:   1.00\n        Usable SNR:       1.00\n        Dropout Fraction: 0.00\n</code></pre> <p>The output HDF5 file will have the following structure:</p> <pre><code>/\n\u251c\u2500\u2500 2A3/\n\u2502   \u251c\u2500\u2500 ROI\n\u2502   \u251c\u2500\u2500 SNR\n\u2502   \u251c\u2500\u2500 error\n\u2502   \u251c\u2500\u2500 heatmap\n\u2502   \u251c\u2500\u2500 norm\n\u2502   \u251c\u2500\u2500 reactivity\n\u2502   \u2514\u2500\u2500 reads\n\u2514\u2500\u2500 DMS/\n    \u251c\u2500\u2500 ROI\n    \u251c\u2500\u2500 SNR\n    \u251c\u2500\u2500 error\n    \u251c\u2500\u2500 heatmap\n    \u251c\u2500\u2500 norm\n    \u251c\u2500\u2500 reactivity\n    \u2514\u2500\u2500 reads\n</code></pre> <p>If you wish to overlay the reactivity profile onto a 3D structure stored in <code>CIF</code>, then you may then run</p> <pre><code>for ((IX=0; IX&lt;${#NAMES[@]}; IX++)); do\n  NAME=${NAMES[IX]}\n  cmuts visualize \\\n    --file \"$PROFILES\" \\\n    --dataset \"$NAME\" \\\n    --fasta \"$FASTA\" \\\n    --cif \"$CIF\"\ndone\n</code></pre>"},{"location":"usage/examples/#with-demultiplexing","title":"With Demultiplexing","text":"<pre><code>PARENT=\"examples/map-seq-dmux\"\n</code></pre> <p>The main difference when working with FASTQ files which must be demultiplexed first is that <code>MODS</code> and <code>NOMODS</code> should refer to the barcodes for each condition, rather than the files themselves.</p> <pre><code>MODS=(\"GCCTGGGTGGCT\", \"TGACCATGTATA\")\nNOMODS=(\"AAGGACCACTGG\", \"CTTATTACACAC\")\nNAMES=(\"2A3\", \"DMS\")\n</code></pre> <p>We use a different directory of FASTQ files for this example. Naturally, in addition to the previous inputs, a comma-separated file containing the barcodes to use for demultiplexing must be provided to <code>cmuts align</code>.</p> <pre><code>FASTQ=\"$PARENT/fastq\"\nFASTA=\"$PARENT/ref.fasta\"\nBARCODES=\"$PARENT/barcodes.fasta\"\n</code></pre> <p>Otherwise, the pipeline remains the same:</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --barcodes \"$BARCODES\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n\ncmuts core \\\n  -f \"$FASTA\" \\\n  -o \"$COUNTS\" \\\n  --no-insertions \\\n  \"$ALIGNMENTS\"/*\n\nfor ((IX=0; IX&lt;${#MODS[@]}; IX++)); do\n  MOD_DS=\"$ALIGNMENTS\"/${MODS[IX]}\n  NOMOD_DS=\"$ALIGNMENTS\"/${NOMODS[IX]}\n  NAME=${NAMES[IX]}\n  cmuts normalize \\\n    -o \"$PROFILES\" \\\n    --mod \"$MOD_DS\" \\\n    --nomod \"$NOMOD_DS\" \\\n    --group \"$NAME\" \\\n    \"$COUNTS\"\ndone\n</code></pre>"},{"location":"usage/examples/#two-dimensional-map-seq","title":"Two-Dimensional MaP-seq","text":""},{"location":"usage/examples/#residue-residue-correlations","title":"Residue-Residue Correlations","text":"<pre><code>PARENT=\"examples/mohca\"\n</code></pre> <p>This example uses MOHCA-seq data.</p> <pre><code>FASTQ=\"$PARENT/fastq\"\nFASTA=\"$PARENT/ref.fasta\"\n</code></pre> <p>The first two steps are the same, save for the <code>--joint</code> flag passed to <code>cmuts core</code>.</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n\ncmuts core \\\n  --joint \\\n  -f \"$FASTA\" \\\n  -o \"$COUNTS\" \\\n  --no-insertions \\\n  \"$ALIGNMENTS\"/*\n</code></pre> <p>The third step uses <code>cmuts pairwise</code> to postprocess the 2D data.</p> <pre><code>for ((IX=0; IX&lt;${#MODS[@]}; IX++)); do\n  MOD_DS=\"$ALIGNMENTS\"/${MODS[IX]}\n  cmuts pairwise \\\n    -o \"$PROFILES\" \\\n    --dataset \"$MOD_DS\" \\\n    --mutual-information \\\n    \"$COUNTS\"\ndone\n</code></pre>"},{"location":"usage/examples/#mutate-and-map","title":"Mutate-And-Map","text":"<pre><code>PARENT=\"examples/m2\"\n</code></pre> <pre><code>FASTQ=\"$PARENT/fastq\"\nFASTA=\"$PARENT/ref.fasta\"\n</code></pre>"},{"location":"usage/pipeline/","title":"The Pipeline","text":"<p>The <code>cmuts</code> pipeline consists of three independent programs:</p> <ol> <li>The <code>cmuts align</code> wrapper,</li> <li>The <code>cmuts core</code> program, and</li> <li>Either <code>cmuts normalize</code> or <code>cmuts pairwise</code>, depending on whether 1D or 2D MaP-seq is being performed.</li> </ol> <p>Warning</p> <p>Some sequencing vendors (e.g. Ultima) will provide pre-aligned BAM/CRAM files. In such a case, simply ignore the <code>cmuts align</code> step.</p>"}]}