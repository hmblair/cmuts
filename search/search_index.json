{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#cmuts","title":"cmuts","text":"<p>Fast mutation counting and reactivity profiling for MaP-seq experiments.</p> <p></p>"},{"location":"#overview","title":"Overview","text":"<p><code>cmuts</code> is a high-performance program designed for analyzing MaP-seq (Mutational Profiling with sequencing) experiments. It provides comprehensive tools for counting mutations and computing reactivity profiles with exceptional speed and accuracy.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>:material-flash: Fast, compiled C++ code with native multithreading support</li> <li>:material-harddisk: Streamed IO and direct output to compressed HDF5 files  </li> <li>:material-dna: Advanced deletion handling including arbitrary-length ambiguous deletions with mutation-informed spreading</li> <li>:material-cog: Four independent processing steps for complete analysis workflow</li> </ul>"},{"location":"#workflow-components","title":"Workflow Components","text":"<p>cmuts performs analysis through four main components:</p> <ol> <li>Modification Counting - Identify and count mutations in aligned sequencing reads</li> <li>Normalization - Compute normalized reactivity profiles using <code>cmuts-normalize</code></li> <li>Tokenization - Convert reference sequences to numerical tokens (optional)</li> <li>Joint Analysis - Analyze co-occurring modifications across positions (optional)</li> </ol>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get up and running with cmuts in just a few commands:</p> <pre><code># Basic mutation counting\ncmuts -o output.h5 -f reference.fasta aligned_reads.bam\n\n# Recommended for standard MaP-seq analysis\ncmuts -o output.h5 -f reference.fasta aligned_reads.bam \\\n    --no-insertions \\\n    --filter-coverage\n\n# Parallel processing with MPI\nmpirun -np 8 cmuts -o output.h5 -f reference.fasta aligned_reads.bam\n</code></pre>"},{"location":"#what-you-need","title":"What You Need","text":"<p>To get started with cmuts, you'll need:</p> <ul> <li>Reference sequences in FASTA format</li> <li>Aligned reads in SAM/BAM/CRAM format</li> <li>Index files (<code>.bai</code> or <code>.crai</code>) - created automatically if missing</li> </ul> <p>File Preparation</p> <p>If your alignment file isn't sorted, cmuts will automatically call <code>samtools sort</code> to prepare it for analysis.</p>"},{"location":"#output-format","title":"Output Format","text":"<p>cmuts generates HDF5 files containing mutation count data with dimensions <code>n \u00d7 l \u00d7 4 \u00d7 7</code>, where:</p> <ul> <li><code>n</code> = number of reference sequences</li> <li><code>l</code> = maximum sequence length</li> <li><code>4</code> = original base types (A, C, G, T)</li> <li><code>7</code> = mutation types (A, C, G, T substitutions + insertions + deletions + matches)</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation Requirements - System requirements and dependencies</li> <li>Basic Installation - Step-by-step installation guide</li> <li>Usage Examples - Detailed usage scenarios and examples</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>:material-github: Issues: Report bugs or request features</li> <li>:material-file-document: Documentation: Complete guides and API reference</li> <li>:material-email: Contact: Reach out for questions or collaboration</li> </ul> <p>cmuts is designed for researchers working with MaP-seq data who need fast, accurate mutation analysis with minimal computational overhead.</p>"},{"location":"installation/installation/","title":"Installation","text":""},{"location":"installation/installation/#basic-installation","title":"Basic Installation","text":"<p>This page covers the installation of the single-threaded version of <code>cmuts</code>. Before starting, ensure you have all required dependencies installed on your system.</p> <p>Verify Dependencies</p> <p>Run these commands to verify your system is ready: </p><pre><code>cmake --version               # Should be 3.29+\nsamtools --version            # Should show version info\nautoreconf --version          # Should show version info\npkg-config --modversion hdf5  # Should show HDF5 version\n</code></pre><p></p>"},{"location":"installation/installation/#installation","title":"Installation","text":""},{"location":"installation/installation/#1-obtain-cmuts","title":"1. Obtain <code>cmuts</code>","text":"<p>Clone the <code>cmuts</code> repository with all submodules:</p> <pre><code>git clone --recurse-submodules https://github.com/hmblair/cmuts\ncd cmuts\n</code></pre>"},{"location":"installation/installation/#2-build-cmuts","title":"2. Build <code>cmuts</code>","text":"<p>The configuration script contains all required setup and build steps.</p> <pre><code>./configure\n</code></pre> <p>If building the multithreaded version, pass the <code>--mpi</code> flag to the script.</p> <pre><code>./configure --mpi\n</code></pre>"},{"location":"installation/installation/#3-modify-path","title":"3. Modify PATH","text":"<p>Afterwards, add the <code>cmuts</code> binary directory to your PATH:</p> Temporary (current session)Permanent (bash)Permanent (zsh) <pre><code>export PATH=\"$(pwd)/bin:$PATH\"\n</code></pre> <pre><code>echo 'export PATH=\"'$(pwd)'/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <pre><code>echo 'export PATH=\"'$(pwd)'/bin:$PATH\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"installation/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/installation/#common-build-issues","title":"Common Build Issues","text":"<p>cmake cannot find HDF5</p> <p>Solution: Set the HDF5_DIR environment variable </p><pre><code># For Homebrew on macOS\nexport HDF5_DIR=$(brew --prefix hdf5)\n./configure\n\n# For Ubuntu/Debian\nexport HDF5_DIR=/usr/lib/x86_64-linux-gnu/hdf5/serial\n./configure\n</code></pre><p></p> <p>samtools not found</p> <p>Solution: Ensure samtools is in your PATH </p><pre><code>which samtools  # Should return a path\n# If not found, install via package manager or add to PATH\n</code></pre><p></p> <p>autoconf missing</p> <p>Solution: Install autoconf </p><pre><code># macOS\nbrew install autoconf\n\n# Ubuntu/Debian\nsudo apt install autoconf\n</code></pre><p></p> <p>submodules not initialized</p> <p>Error: <code>fatal: not a git repository</code> during build</p> <p>Solution: Ensure you cloned with submodules </p><pre><code>git submodule update --init --recursive\n./configure\n</code></pre><p></p>"},{"location":"installation/installation/#hdf5-library-issues","title":"HDF5 Library Issues","text":"<p>If you have multiple HDF5 installations:</p> <pre><code># Find HDF5 installations\nfind /usr -name \"libhdf5*\" 2&gt;/dev/null\nfind /opt -name \"libhdf5*\" 2&gt;/dev/null\n\n# Set specific installation\nexport HDF5_DIR=/path/to/preferred/hdf5\n./configure\n</code></pre>"},{"location":"installation/installation/#next-steps","title":"Next Steps","text":"<p>Now that cmuts is installed:</p> <ol> <li>Quick Start Guide - Learn basic usage</li> <li>Command Line Options - Explore all available options</li> <li>MPI Installation - Upgrade to parallel processing (optional)</li> <li>Testing - Run comprehensive tests</li> </ol>"},{"location":"installation/installation/#updating-cmuts","title":"Updating cmuts","text":"<p>To update to a newer version:</p> <pre><code>cd cmuts\ngit pull origin master\ngit submodule update --recursive\n./configure\n</code></pre> <p>Clean Builds</p> <p>If you encounter issues after updating, try a clean build: </p><pre><code>rm -rf build/ bin/\n./configure\n</code></pre><p></p>"},{"location":"installation/org-notes/","title":"Organization-Specific Notes","text":"<p>The following is an incomplete list of various locations where <code>cmuts</code> has been run, and the specific requirements for each one.</p>"},{"location":"installation/org-notes/#stanford-sherlock-cluster","title":"Stanford Sherlock Cluster","text":"<p>Both building and running will require the following, which covers all dependencies.</p> <pre><code>ml load hdf5/1.14.4\nml load biology samtools/1.16.1\nml load cmake/3.31.4\n</code></pre>"},{"location":"installation/org-notes/#hhmi-janelia-cluster","title":"HHMI Janelia Cluster","text":"<p>Running will require the following two commands.</p> <pre><code>ml load samtools\nLD_LIBRARY_PATH=/misc/local/samtools-1.22.1/lib:$LD_LIBRARY_PATH\n</code></pre> <p>In addition, building <code>cmuts</code> will require</p> <pre><code>ml load cmake/4.0.2\nexport PKG_CONFIG_PATH=/misc/local/samtools-1.22.1/lib/pkgconfig:$PKG_CONFIG_PATH\n</code></pre>"},{"location":"installation/requirements/","title":"Requirements","text":"<pre><code># Requirements\n\nThis page outlines the system requirements and dependencies needed to build and run cmuts.\n\n## System Requirements\n\n### Operating Systems\n\ncmuts is supported on:\n\n- **Linux**\n- **macOS** (Intel and ARM)\n\n## Core Dependencies\n\n### Required for Basic Installation\n\n| Dependency | Minimum Version | Purpose |\n|------------|----------------|---------|\n| **cmake** | 3.29+ | Build system |\n| **samtools** | 1.10+ | SAM/BAM/CRAM file handling |\n| **HTSlib** | 1.10+ | High-throughput sequencing data |\n| **HDF5** | 1.10+ | Output file format |\n| **autoconf** | 2.69+ | Building htscodecs dependency |\n\n### Additional for MPI Support\n\n| Dependency | Purpose |\n|------------|---------|\n| **OpenMPI** | Parallel processing |\n| **HDF5 with parallel support** | Parallel HDF5 I/O |\n\n## Installation Methods\n\n### Package Managers\n\n=== \"Homebrew (macOS/Linux)\"\n    ```bash\n    brew install cmake samtools hdf5 autoconf\n\n    # For MPI support\n    brew install hdf5-mpi open-mpi\n    ```\n\n=== \"Ubuntu/Debian\"\n    ```bash\n    sudo apt update\n    sudo apt install cmake samtools libhts-dev libhdf5-dev autoconf\n\n    # For MPI support\n    sudo apt install libhdf5-openmpi-dev openmpi-bin libopenmpi-dev\n    ```\n\n=== \"CentOS/RHEL\"\n    ```bash\n    sudo yum install cmake samtools htslib-devel hdf5-devel autoconf\n\n    # For MPI support  \n    sudo yum install hdf5-openmpi-devel openmpi-devel\n    ```\n\n## Python Dependencies (for cmuts-normalize)\n\nThe normalization component requires:\n\n- **Python**: 3.10 or higher\n- **Packages**: Listed in `requirements.txt`\n\n```bash\npip install -r requirements.txt\n</code></pre>"},{"location":"installation/requirements/#environment-variables","title":"Environment Variables","text":""},{"location":"installation/requirements/#hdf5-configuration","title":"HDF5 Configuration","text":"<p>If cmake has trouble finding your HDF5 installation:</p> <pre><code>export HDF5_DIR=/path/to/hdf5/installation\n</code></pre>"},{"location":"installation/requirements/#for-custom-installations","title":"For Custom Installations","text":"<pre><code># Add to your shell profile (.bashrc, .zshrc, etc.)\nexport CMAKE_PREFIX_PATH=\"/usr/local:$CMAKE_PREFIX_PATH\"\nexport PKG_CONFIG_PATH=\"/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH\"\n</code></pre>"},{"location":"installation/requirements/#verification","title":"Verification","text":""},{"location":"installation/requirements/#check-dependencies","title":"Check Dependencies","text":"<p>Verify your installations:</p> <pre><code># Check versions\ncmake --version        # Should be 3.29+\nsamtools --version     # Should show version info\npkg-config --modversion hdf5    # Should show HDF5 version\n\n# Check MPI (if needed)\nmpirun --version       # Should show OpenMPI version\n</code></pre>"},{"location":"installation/requirements/#test-hdf5","title":"Test HDF5","text":"<pre><code># Test basic HDF5 functionality\nh5dump --version\n</code></pre>"},{"location":"installation/requirements/#common-issues","title":"Common Issues","text":"<p>HDF5 Detection Problems</p> <p>If cmake cannot find HDF5, try: </p><pre><code>export HDF5_DIR=$(brew --prefix hdf5)  # macOS with Homebrew\n# or\nexport HDF5_DIR=/usr/lib/x86_64-linux-gnu/hdf5/serial  # Ubuntu\n</code></pre><p></p> <p>Samtools Version</p> <p>Older versions of samtools may not support all CRAM features. We recommend version 1.15 or newer for best compatibility.</p> <p>MPI vs Single-threaded</p> <p>You can install and use the single-threaded version first, then add MPI support later if needed. The basic version is sufficient for most use cases.</p>"},{"location":"installation/requirements/#next-steps","title":"Next Steps","text":"<p>Once you have all dependencies installed:</p> <ol> <li>Basic Installation - Build the single-threaded version</li> <li>MPI Installation - Add parallel processing support</li> <li>Quick Start Guide - Begin using cmuts</li> </ol>"},{"location":"usage/cmuts/","title":"cmuts","text":""},{"location":"usage/cmuts/#cmuts","title":"cmuts","text":""},{"location":"usage/cmuts/#basic-usage","title":"Basic Usage","text":""},{"location":"usage/cmuts/#required-inputs","title":"Required Inputs","text":"<p><code>cmuts</code> requires two inputs to run:</p> <ol> <li>Reference sequences, stored in a FASTA file,</li> <li>Aligned reads, stored in one or more SAM/BAM/CRAM files</li> </ol>"},{"location":"usage/cmuts/#syntax","title":"Syntax","text":"<p>A generic call to <code>cmuts</code> will look like </p><pre><code>cmuts -o OUTPUT -f FASTA [OPTIONAL ARGUMENTS] FILE\n</code></pre><p></p>"},{"location":"usage/cmuts/#modification-counting","title":"Modification Counting","text":"<p>To count modifications in a single aligned HTS file:</p> <pre><code>cmuts -o out.h5 -f seq.fasta sorted.bam\n</code></pre> <p>For the MPI-enabled version, use multiple threads:</p> <pre><code>mpirun -np 8 cmuts -o out.h5 -f seq.fasta sorted.bam\n</code></pre> <p>Multiple SAM/BAM/CRAM files can be processed simultaneously:</p> <pre><code>mpirun -np 8 cmuts -o out.h5 -f seq.fasta sorted1.bam sorted2.bam ...\n</code></pre>"},{"location":"usage/cmuts/#required-inputs_1","title":"Required Inputs","text":"<ol> <li>Reference sequences: A FASTA file specified with the <code>-f</code> option</li> <li>Aligned reads: One or more SAM/BAM/CRAM files</li> </ol> <p>The program will automatically create necessary index files (.bai or .crai) and a custom binary .binfa file from the FASTA file. If input files are not sorted, <code>samtools sort</code> will be called automatically.</p>"},{"location":"usage/cmuts/#output-format","title":"Output Format","text":"<p>The output HDF5 file contains one dataset per input file, named by the file path (without extension). Each dataset has shape <code>n \u00d7 l \u00d7 4 \u00d7 7</code> where:</p> <ul> <li><code>n</code> = number of sequences</li> <li><code>l</code> = maximum sequence length  </li> <li>Dimension 2 = original base (A, C, G, T)</li> <li>Dimension 3 = mutated base or inserted base</li> </ul>"},{"location":"usage/cmuts/#command-line-options","title":"Command Line Options","text":""},{"location":"usage/cmuts/#core-options","title":"Core Options","text":"<p><code>-o, --output</code> : Output HDF5 filename (required)</p> <p><code>-f, --fasta</code> : Reference FASTA file (required)</p>"},{"location":"usage/cmuts/#output-control","title":"Output Control","text":"<p><code>--overwrite</code> : Overwrite existing HDF5 file</p> <p><code>--compression</code> : HDF5 compression level (0-9, default: 3)</p>"},{"location":"usage/cmuts/#analysis-modes","title":"Analysis Modes","text":"<p><code>--tokenize</code> : Tokenize reference sequences and store in <code>sequence</code> dataset</p> <p><code>--joint</code> : Compute joint distribution of mutations over all position pairs</p> <p><code>--low-mem</code> : Record only modification locations and coverage (not type), reducing memory usage by 2x+</p>"},{"location":"usage/cmuts/#quality-filtering","title":"Quality Filtering","text":"<p><code>--min-mapq</code> : Mapping quality threshold (default: 10)</p> <p><code>--min-phred</code> : PHRED score threshold (default: 10)</p> <p><code>--quality-window</code> : Quality check window size around each base (default: 2)</p> <p><code>--min-length</code> : Minimum alignment length (default: 2)</p> <p><code>--max-length</code> : Maximum alignment length (default: 10,000)</p>"},{"location":"usage/cmuts/#modification-detection","title":"Modification Detection","text":"<p><code>--max-indel-length</code> : Maximum indel length to consider (default: 10)</p> <p><code>--collapse</code> : Collapse modifications within this distance in a read (default: 2)</p> <p><code>--no-mismatches</code> : Exclude mismatches from modification counts</p> <p><code>--no-insertions</code> : Exclude insertions from modification counts (recommended for MaP-seq)</p> <p><code>--no-deletions</code> : Exclude deletions from modification counts</p>"},{"location":"usage/cmuts/#deletion-handling","title":"Deletion Handling","text":"<p><code>--uniform-spread</code> : Uniformly spread ambiguous deletions</p> <p><code>--mutation-spread</code> : Spread ambiguous deletions according to existing mutation profile</p> <p><code>--disable-ambiguous</code> : Use alignment-provided deletions only</p> <p><code>--contiguous-ambiguous</code> : Allow only contiguous regions as ambiguous deletions</p>"},{"location":"usage/cmuts/#sampling-and-coverage","title":"Sampling and Coverage","text":"<p><code>--subsample</code> : Random read acceptance probability (default: 1.0)</p> <p><code>--filter-coverage</code> : Apply modification filters to matches (recommended for MaP-seq)</p>"},{"location":"usage/cmuts/#performance","title":"Performance","text":"<p><code>--chunk-size</code> : Internal buffer size per thread in references (default: 128)</p> <p><code>--print-every</code> : Progress update frequency in reads processed (default: 1,000)</p>"},{"location":"usage/cmuts/#example-use-cases","title":"Example Use Cases","text":""},{"location":"usage/cmuts/#tokenization-only","title":"Tokenization Only","text":"<p>Generate tokenized sequences without processing alignments:</p> <pre><code>cmuts --tokenize -f seq.fasta -o counts.h5\n</code></pre>"},{"location":"usage/cmuts/#joint-modification-analysis","title":"Joint Modification Analysis","text":"<p>Compute joint modification distributions:</p> <pre><code>cmuts --joint -o joint.h5 -f seq.fasta sorted.bam\n</code></pre> <p>Output shape: <code>n \u00d7 l \u00d7 l \u00d7 2 \u00d7 2</code> where the final dimensions indicate modification presence (1) or absence (0) at each position pair.</p>"},{"location":"usage/cmuts/#memory-efficient-analysis","title":"Memory-Efficient Analysis","text":"<p>For large datasets, use low-memory mode:</p> <pre><code>cmuts --low-mem -o out.h5 -f seq.fasta sorted.bam\n</code></pre>"},{"location":"usage/cmuts/#recommended-map-seq-settings","title":"Recommended MaP-seq Settings","text":"<p>For standard MaP-seq analysis, use:</p> <pre><code>cmuts --no-insertions --filter-coverage -o out.h5 -f seq.fasta sorted.bam\n</code></pre> <p>These flags: - Exclude insertions which are not relevant for chemical modification detection - Apply consistent quality filters to both modifications and coverage calculations</p>"},{"location":"usage/examples/","title":"Examples","text":""},{"location":"usage/examples/#overview","title":"Overview","text":""},{"location":"usage/examples/#environment-setup","title":"Environment Setup","text":"<p>These variables will be used throughout the examples; feel free to set them to a value appropriate for your computer. The latter three specify the location of various intermediate files and outputs from the pipeline.</p> <pre><code>THREADS=8\nALIGNMENTS=\"examples/alignments\"\nCOUNTS=\"examples/counts.h5\"\nPROFILES=\"examples/profiles.h5\"\n</code></pre> <p>All files used in these examples can be found in the repo, under <code>examples</code>.</p>"},{"location":"usage/examples/#pipeline-steps","title":"Pipeline Steps","text":"<p>The <code>cmuts</code> pipeline consists of three parts:</p> <ol> <li>The <code>cmuts align</code> wrapper,</li> <li>The <code>cmuts core</code> program, and</li> <li>Either <code>cmuts normalize</code> or <code>cmuts cov</code>, depending on whether 1D or 2D MaP-seq is being performed.</li> </ol>"},{"location":"usage/examples/#map-seq","title":"MaP-seq","text":"<p>A directory of FASTQ files and a reference FASTA file is required.</p> <pre><code>FASTQ=\"examples/map-seq/fastq\"\nFASTA=\"examples/map-seq/ref.fasta\"\n</code></pre> <p>In addition, <code>cmuts normalize</code> will need to know which datasets correspond to which condition. How this is specified depends on whether demultiplexing is performed or not.</p>"},{"location":"usage/examples/#without-demultiplexing","title":"Without Demultiplexing","text":"<p>The following arrays contain the basenames of the FASTQ files corresponding to each condition. A parallel array containing the name of each condition is necessary as well.</p> <pre><code>MODS=(\"bicine-2A3\", \"bicine-DMS\")\nNOMODS=(\"bicine-DMSO\", \"bicine-ETH\")\nNAMES=(\"2A3\", \"DMS\")\n</code></pre> <p><code>NOMODS</code> may be empty, in the case where background subtraction is not to be performed.</p> <p>One can run <code>cmuts align</code> directly on the FASTQ files and then pass the output to <code>cmuts core</code> to locate modifications.</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n\ncmuts core \\\n  -f \"$FASTA\" \\\n  -o \"$COUNTS\" \\\n  --filter-coverage \\\n  --no-insertions \\\n  \"$ALIGNMENTS\"/*\n</code></pre> <p>This will output a single HDF5 file, <code>$COUNTS</code>, which will contain one dataset for each input. One can then loop over all input files, and pass the respective dataset to <code>cmuts normalize</code>.</p> <pre><code>for ((IX=0; IX&lt;${#MODS[@]}; IX++)); do\n  MOD_DS=\"$ALIGNMENTS\"/${MODS[IX]}\n  NOMOD_DS=\"$ALIGNMENTS\"/${NOMODS[IX]}\n  NAME=${NAMES[IX]}\n  cmuts normalize \\\n    -o \"$PROFILES\" \\\n    --mod \"$MOD_DS\" \\\n    --nomod \"$NOMOD_DS\" \\\n    --group \"$NAME\" \\\n    $COUNTS\"\ndone\n</code></pre>"},{"location":"usage/examples/#with-demultiplexing","title":"With Demultiplexing","text":"<p>The main difference when working with FASTQ files which must be demultiplexed first is that <code>MODS</code> and <code>NOMODS</code> should refer to the barcodes for each condition, rather than the files themselves.</p> <pre><code>MODS=(\"GCCTGGGTGGCT\", \"TGACCATGTATA\")\nNOMODS=(\"AAGGACCACTGG\", \"CTTATTACACAC\")\nNAMES=(\"2A3\", \"DMS\")\n</code></pre> <p>We use a different directory of FASTQ files for this example. Naturally, in addition to the previous inputs, a comma-separated file containing the barcodes to use for demultiplexing must be provided to <code>cmuts align</code>.</p> <pre><code>FASTQ=\"examples/map-seq/fastq-dmux\"\nFASTA=\"examples/map-seq/ref.fasta\"\nBARCODES=\"examples/map-seq/barcodes.fasta\"\n</code></pre> <p>Otherwise, the pipeline remains the same:</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --barcodes \"$BARCODES\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n\ncmuts core \\\n  -f \"$FASTA\" \\\n  -o \"$COUNTS\" \\\n  --filter-coverage \\\n  --no-insertions \\\n  \"$ALIGNMENTS\"/*\n\nfor ((IX=0; IX&lt;${#MODS[@]}; IX++)); do\n  MOD_DS=\"$ALIGNMENTS\"/${MODS[IX]}\n  NOMOD_DS=\"$ALIGNMENTS\"/${NOMODS[IX]}\n  NAME=${NAMES[IX]}\n  cmuts normalize \\\n    -o \"$PROFILES\" \\\n    --mod \"$MOD_DS\" \\\n    --nomod \"$NOMOD_DS\" \\\n    --group \"$NAME\" \\\n    $COUNTS\"\ndone\n</code></pre>"},{"location":"usage/examples/#two-dimensional-map-seq","title":"Two-Dimensional MaP-seq","text":""},{"location":"usage/examples/#residue-residue-correlations","title":"Residue-Residue Correlations","text":"<p>This example uses MOHCA-seq data.</p> <pre><code>FASTQ=\"examples/mohca/fastq\"\nFASTA=\"examples/mohca/ref.fasta\"\n</code></pre> <p>The first two steps are the same, save for the <code>--joint</code> flag passed to <code>cmuts core</code>.</p> <pre><code>cmuts align \\\n  --fasta \"$FASTA\" \\\n  --threads \"$THREADS\" \\\n  --output \"$ALIGNMENTS\" \\\n  \"$FASTQ\"/*.fastq*\n\ncmuts core \\\n  --joint \\\n  -f \"$FASTA\" \\\n  -o \"$COUNTS\" \\\n  --filter-coverage \\\n  --no-insertions \\\n  \"$ALIGNMENTS\"/*\n</code></pre> <p>The third step uses <code>cmuts cov</code> to postprocess the 2D data.</p> <pre><code>for ((IX=0; IX&lt;${#MODS[@]}; IX++)); do\n  MOD_DS=\"$ALIGNMENTS\"/${MODS[IX]}\n  cmuts cov \\\n    -o \"$PROFILES\" \\\n    --dataset \"$MOD_DS\" \\\n    --mutual-information \\\n    $COUNTS\"\ndone\n</code></pre>"},{"location":"usage/examples/#mutate-and-map","title":"Mutate-And-Map","text":"<pre><code>FASTQ=\"examples/m2/fastq\"\nFASTA=\"examples/m2/ref.fasta\"\n</code></pre>"}]}