{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#cmuts","title":"cmuts","text":"<p>Fast mutation counting and reactivity profiling for MaP-seq experiments.</p> <p></p>"},{"location":"#overview","title":"Overview","text":"<p><code>cmuts</code> is a high-performance program designed for analyzing MaP-seq (Mutational Profiling with sequencing) experiments. It provides comprehensive tools for counting mutations and computing reactivity profiles with exceptional speed and accuracy.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>:material-flash: Fast, compiled C++ code with native multithreading support</li> <li>:material-harddisk: Streamed IO and direct output to compressed HDF5 files  </li> <li>:material-dna: Advanced deletion handling including arbitrary-length ambiguous deletions with mutation-informed spreading</li> <li>:material-cog: Four independent processing steps for complete analysis workflow</li> </ul>"},{"location":"#workflow-components","title":"Workflow Components","text":"<p>cmuts performs analysis through four main components:</p> <ol> <li>Modification Counting - Identify and count mutations in aligned sequencing reads</li> <li>Normalization - Compute normalized reactivity profiles using <code>cmuts-normalize</code></li> <li>Tokenization - Convert reference sequences to numerical tokens (optional)</li> <li>Joint Analysis - Analyze co-occurring modifications across positions (optional)</li> </ol>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get up and running with cmuts in just a few commands:</p> <pre><code># Basic mutation counting\ncmuts -o output.h5 -f reference.fasta aligned_reads.bam\n\n# Recommended for standard MaP-seq analysis\ncmuts -o output.h5 -f reference.fasta aligned_reads.bam \\\n    --no-insertions \\\n    --filter-coverage\n\n# Parallel processing with MPI\nmpirun -np 8 cmuts -o output.h5 -f reference.fasta aligned_reads.bam\n</code></pre>"},{"location":"#what-you-need","title":"What You Need","text":"<p>To get started with cmuts, you'll need:</p> <ul> <li>Reference sequences in FASTA format</li> <li>Aligned reads in SAM/BAM/CRAM format</li> <li>Index files (<code>.bai</code> or <code>.crai</code>) - created automatically if missing</li> </ul> <p>File Preparation</p> <p>If your alignment file isn't sorted, cmuts will automatically call <code>samtools sort</code> to prepare it for analysis.</p>"},{"location":"#output-format","title":"Output Format","text":"<p>cmuts generates HDF5 files containing mutation count data with dimensions <code>n \u00d7 l \u00d7 4 \u00d7 7</code>, where:</p> <ul> <li><code>n</code> = number of reference sequences</li> <li><code>l</code> = maximum sequence length</li> <li><code>4</code> = original base types (A, C, G, T)</li> <li><code>7</code> = mutation types (A, C, G, T substitutions + insertions + deletions + matches)</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation Requirements - System requirements and dependencies</li> <li>Basic Installation - Step-by-step installation guide</li> <li>Usage Examples - Detailed usage scenarios and examples</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>:material-github: Issues: Report bugs or request features</li> <li>:material-file-document: Documentation: Complete guides and API reference</li> <li>:material-email: Contact: Reach out for questions or collaboration</li> </ul> <p>cmuts is designed for researchers working with MaP-seq data who need fast, accurate mutation analysis with minimal computational overhead.</p>"},{"location":"installation/basic-installation/","title":"Basic Installation","text":""},{"location":"installation/basic-installation/#basic-installation","title":"Basic Installation","text":"<p>This guide covers the installation of the single-threaded version of cmuts, which is suitable for most users and provides excellent performance for typical datasets.</p>"},{"location":"installation/basic-installation/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have all required dependencies installed on your system.</p> <p>Verify Dependencies</p> <p>Run these commands to verify your system is ready: </p><pre><code>cmake --version               # Should be 3.29+\nsamtools --version            # Should show version info\nautoreconf --version          # Should show version info\npkg-config --modversion hdf5  # Should show HDF5 version\n</code></pre><p></p>"},{"location":"installation/basic-installation/#installation-steps","title":"Installation Steps","text":""},{"location":"installation/basic-installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>Clone the cmuts repository with all submodules:</p> <pre><code>git clone --recurse-submodules https://github.com/hmblair/cmuts\ncd cmuts\n</code></pre> <p>Don't Forget Submodules</p> <p>The <code>--recurse-submodules</code> flag is essential as cmuts depends on several git submodules. Without this flag, the build will fail.</p>"},{"location":"installation/basic-installation/#2-build-the-program","title":"2. Build the Program","text":"<p>Run the configuration script:</p> <pre><code>./configure\n</code></pre> <p>This script will:</p> <ul> <li>Build the <code>htscodecs</code> dependency</li> <li>Configure <code>cmake</code> with appropriate settings</li> <li>Detect your system's HDF5 and <code>samtools</code> installations</li> <li>Build <code>cmuts</code> and <code>cmuts-generate-tests</code></li> </ul> <p>If successful, you'll see:</p> <pre><code>-- Build completed successfully --\n</code></pre>"},{"location":"installation/basic-installation/#3-add-to-path","title":"3. Add to PATH","text":"<p>Add the <code>cmuts</code> binary directory to your PATH:</p> Temporary (current session)Permanent (bash)Permanent (zsh) <pre><code>export PATH=\"$(pwd)/bin:$PATH\"\n</code></pre> <pre><code>echo 'export PATH=\"'$(pwd)'/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <pre><code>echo 'export PATH=\"'$(pwd)'/bin:$PATH\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"installation/basic-installation/#verify-installation","title":"Verify Installation","text":""},{"location":"installation/basic-installation/#test-basic-functionality","title":"Test Basic Functionality","text":"<pre><code># Check that cmuts is available\ncmuts --help\n\n# Run the built-in synthetic tests\n./tests/syn/run\n</code></pre>"},{"location":"installation/basic-installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/basic-installation/#common-build-issues","title":"Common Build Issues","text":"<p>cmake cannot find HDF5</p> <p>Solution: Set the HDF5_DIR environment variable </p><pre><code># For Homebrew on macOS\nexport HDF5_DIR=$(brew --prefix hdf5)\n./configure\n\n# For Ubuntu/Debian\nexport HDF5_DIR=/usr/lib/x86_64-linux-gnu/hdf5/serial\n./configure\n</code></pre><p></p> <p>samtools not found</p> <p>Solution: Ensure samtools is in your PATH </p><pre><code>which samtools  # Should return a path\n# If not found, install via package manager or add to PATH\n</code></pre><p></p> <p>autoconf missing</p> <p>Solution: Install autoconf </p><pre><code># macOS\nbrew install autoconf\n\n# Ubuntu/Debian\nsudo apt install autoconf\n</code></pre><p></p> <p>submodules not initialized</p> <p>Error: <code>fatal: not a git repository</code> during build</p> <p>Solution: Ensure you cloned with submodules </p><pre><code>git submodule update --init --recursive\n./configure\n</code></pre><p></p>"},{"location":"installation/basic-installation/#hdf5-library-issues","title":"HDF5 Library Issues","text":"<p>If you have multiple HDF5 installations:</p> <pre><code># Find HDF5 installations\nfind /usr -name \"libhdf5*\" 2&gt;/dev/null\nfind /opt -name \"libhdf5*\" 2&gt;/dev/null\n\n# Set specific installation\nexport HDF5_DIR=/path/to/preferred/hdf5\n./configure\n</code></pre>"},{"location":"installation/basic-installation/#file-locations","title":"File Locations","text":"<p>After successful installation:</p> <pre><code>cmuts/\n\u251c\u2500\u2500 bin/\n\u2502   \u2514\u2500\u2500 cmuts              # Main executable\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 run                # Test runner\n\u2502   \u2514\u2500\u2500 profile            # Performance profiler\n\u251c\u2500\u2500 build/                 # Build artifacts\n\u2514\u2500\u2500 external/              # Built dependencies\n</code></pre>"},{"location":"installation/basic-installation/#next-steps","title":"Next Steps","text":"<p>Now that cmuts is installed:</p> <ol> <li>Quick Start Guide - Learn basic usage</li> <li>Command Line Options - Explore all available options</li> <li>MPI Installation - Upgrade to parallel processing (optional)</li> <li>Testing - Run comprehensive tests</li> </ol>"},{"location":"installation/basic-installation/#updating-cmuts","title":"Updating cmuts","text":"<p>To update to a newer version:</p> <pre><code>cd cmuts\ngit pull origin master\ngit submodule update --recursive\n./configure\n</code></pre> <p>Clean Builds</p> <p>If you encounter issues after updating, try a clean build: </p><pre><code>rm -rf build/ bin/\n./configure\n</code></pre><p></p> <p>```</p>"},{"location":"installation/mpi-installation/","title":"MPI Installation","text":""},{"location":"installation/mpi-installation/#mpi-installation","title":"MPI Installation","text":"<p>This guide covers installing cmuts with MPI (Message Passing Interface) support for parallel processing. MPI installation enables cmuts to utilize multiple CPU cores and potentially multiple nodes for faster processing of large datasets.</p>"},{"location":"installation/mpi-installation/#when-to-use-mpi","title":"When to Use MPI","text":"<p>Consider MPI installation if you have:</p> <ul> <li>Large BAM/CRAM files (&gt;5 GB)</li> <li>Multiple files to process in batch</li> <li>Multi-core systems (8+ cores recommended)</li> <li>High-throughput analysis requirements</li> <li>Cluster computing environment available</li> </ul>"},{"location":"installation/mpi-installation/#prerequisites","title":"Prerequisites","text":""},{"location":"installation/mpi-installation/#basic-dependencies","title":"Basic Dependencies","text":"<p>All basic installation requirements plus:</p> Component Purpose OpenMPI MPI implementation HDF5 with parallel support Parallel HDF5 I/O"},{"location":"installation/mpi-installation/#verify-mpi-installation","title":"Verify MPI Installation","text":"<pre><code># Check MPI installation\nmpirun --version\nmpicc --version\n\n# Check parallel HDF5\nh5pcc --version  # Should be available if HDF5 has parallel support\n</code></pre>"},{"location":"installation/mpi-installation/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/mpi-installation/#method-1-package-managers-recommended","title":"Method 1: Package Managers (Recommended)","text":"Homebrew (macOS)Ubuntu/DebianCentOS/RHEL <pre><code># Install parallel HDF5 and OpenMPI\nbrew install hdf5-mpi open-mpi\n\n# Verify installation\nbrew list hdf5-mpi\nwhich mpirun\n</code></pre> <pre><code># Install MPI and parallel HDF5\nsudo apt update\nsudo apt install openmpi-bin libopenmpi-dev \\\n                 libhdf5-openmpi-dev libhdf5-dev\n\n# Verify installation  \ndpkg -l | grep -E \"(openmpi|hdf5)\"\n</code></pre> <pre><code># Install MPI and parallel HDF5\nsudo yum install openmpi openmpi-devel \\\n                 hdf5-openmpi hdf5-openmpi-devel\n\n# Load MPI module (if using modules)\nmodule load mpi/openmpi-x86_64\n</code></pre>"},{"location":"installation/mpi-installation/#method-2-stanford-sherlock","title":"Method 2: Stanford Sherlock","text":"<pre><code># Load required modules\nml load openmpi/4.1.2\nml load hdf5/1.14.4  # Ensure this has parallel support\nml load cmake/3.31.4\nml load biology samtools/1.16.1\n\n# Verify parallel HDF5\nml show hdf5  # Should mention parallel or MPI support\n</code></pre>"},{"location":"installation/mpi-installation/#building-with-mpi","title":"Building with MPI","text":""},{"location":"installation/mpi-installation/#1-clone-repository","title":"1. Clone Repository","text":"<pre><code>git clone --recurse-submodules https://github.com/hmblair/cmuts\ncd cmuts\n</code></pre>"},{"location":"installation/mpi-installation/#2-configure-for-mpi","title":"2. Configure for MPI","text":"<p>Run the configure script with the MPI flag:</p> <pre><code>./configure --mpi\n</code></pre> <p>This will:</p> <ul> <li>Detect MPI compiler wrappers (<code>mpicc</code>, <code>mpicxx</code>)</li> <li>Configure HDF5 with parallel support</li> <li>Build cmuts with MPI threading capabilities</li> <li>Enable parallel I/O optimizations</li> </ul>"},{"location":"installation/mpi-installation/#3-verify-mpi-build","title":"3. Verify MPI Build","text":"<pre><code># Check that MPI version was built\nfile bin/cmuts  # Should show it's dynamically linked\nldd bin/cmuts | grep mpi  # Should show MPI libraries\n\n# Test MPI functionality\nmpirun -np 2 bin/cmuts --help\n</code></pre>"},{"location":"installation/mpi-installation/#environment-configuration","title":"Environment Configuration","text":""},{"location":"installation/mpi-installation/#mpi-environment-variables","title":"MPI Environment Variables","text":"<p>Set these for optimal performance:</p> <pre><code># Recommended MPI settings\nexport OMPI_MCA_btl_vader_single_copy_mechanism=none\nexport OMPI_MCA_mpi_warn_on_fork=0\n\n# For large datasets\nexport OMPI_MCA_io_romio_cb_read=enable\nexport OMPI_MCA_io_romio_cb_write=enable\n</code></pre>"},{"location":"installation/mpi-installation/#hdf5-parallel-configuration","title":"HDF5 Parallel Configuration","text":"<pre><code># Ensure HDF5 finds MPI\nexport HDF5_CC=$(which mpicc)\nexport HDF5_CLINKER=$(which mpicc)\n\n# For debugging HDF5 parallel I/O (optional)\nexport HDF5_DISABLE_VERSION_CHECK=1\n</code></pre>"},{"location":"installation/mpi-installation/#testing-mpi-installation","title":"Testing MPI Installation","text":""},{"location":"installation/mpi-installation/#basic-mpi-test","title":"Basic MPI Test","text":"<pre><code># Test with 4 processes\nmpirun -np 4 cmuts --help\n\n# Should output help message 4 times (one per process)\n</code></pre>"},{"location":"installation/mpi-installation/#performance-test","title":"Performance Test","text":"<pre><code># Run built-in performance tests\n./tests/profile --mpi\n\n# Compare single-threaded vs MPI performance\ntime cmuts -o test.h5 -f reference.fasta input.bam\ntime mpirun -np 8 cmuts -o test_mpi.h5 -f reference.fasta input.bam\n</code></pre>"},{"location":"installation/mpi-installation/#comprehensive-test-suite","title":"Comprehensive Test Suite","text":"<pre><code># Run tests with MPI\n./tests/run --mpi\n\n# Should show successful completion of all test cases\n</code></pre>"},{"location":"installation/mpi-installation/#usage-examples","title":"Usage Examples","text":""},{"location":"installation/mpi-installation/#basic-parallel-execution","title":"Basic Parallel Execution","text":"<pre><code># Use 8 MPI processes\nmpirun -np 8 cmuts -o output.h5 -f reference.fasta input.bam\n\n# Process multiple files in parallel\nmpirun -np 8 cmuts -o output.h5 -f reference.fasta \\\n    file1.bam file2.bam file3.bam\n</code></pre>"},{"location":"installation/mpi-installation/#cluster-usage","title":"Cluster Usage","text":"<p>For SLURM-based clusters:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=cmuts_analysis\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=16\n#SBATCH --time=04:00:00\n#SBATCH --mem=64G\n\nmodule load openmpi hdf5 samtools\n\nmpirun cmuts -o results.h5 -f reference.fasta large_dataset.bam\n</code></pre>"},{"location":"installation/mpi-installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/mpi-installation/#common-mpi-issues","title":"Common MPI Issues","text":"<p>MPI not found during configure</p> <p>Solution: Ensure MPI is in PATH and try explicit paths </p><pre><code>export CC=$(which mpicc)\nexport CXX=$(which mpicxx)\n./configure --mpi\n</code></pre><p></p> <p>HDF5 lacks parallel support</p> <p>Error: <code>HDF5 was not built with parallel I/O support</code></p> <p>Solution: Install HDF5 with MPI support </p><pre><code># Homebrew\nbrew uninstall hdf5\nbrew install hdf5-mpi\n\n# Ubuntu\nsudo apt install libhdf5-openmpi-dev\n</code></pre><p></p> <p>Runtime MPI errors</p> <p>Error: <code>ORTE_ERROR_LOG: Not found</code></p> <p>Solution: Check MPI installation and PATH </p><pre><code>which mpirun\nmpirun --version\necho $PATH | grep -o mpi\n</code></pre><p></p>"},{"location":"installation/mpi-installation/#performance-issues","title":"Performance Issues","text":"<p>Poor scaling</p> <p>If MPI doesn't improve performance:</p> <ul> <li>Check I/O bottlenecks: Use SSD storage</li> <li>Optimize process count: Try <code>nproc / 2</code> processes</li> <li>Check memory usage: Each process needs adequate RAM</li> <li>Profile with: <code>./tests/profile --mpi -np 4,8,16</code></li> </ul>"},{"location":"installation/mpi-installation/#hdf5-parallel-io-issues","title":"HDF5 Parallel I/O Issues","text":"<p>Debugging HDF5 parallel problems</p> <pre><code># Enable HDF5 debug output\nexport HDF5_DEBUG=all\nmpirun -np 4 cmuts [options]\n\n# Check HDF5 parallel capabilities\nh5pcc -showconfig | grep -i parallel\n</code></pre>"},{"location":"installation/mpi-installation/#optimal-usage-patterns","title":"Optimal Usage Patterns","text":""},{"location":"installation/mpi-installation/#process-count-guidelines","title":"Process Count Guidelines","text":"Dataset Size Recommended Processes &lt; 1 GB 2-4 processes 1-10 GB 4-8 processes 10-50 GB 8-16 processes &gt; 50 GB 16-32 processes <p>Process Count Selection</p> <p>Start with <code>min(file_size_GB, num_cores)</code> processes and adjust based on performance.</p>"},{"location":"installation/mpi-installation/#memory-considerations","title":"Memory Considerations","text":"<pre><code># Monitor memory usage\nmpirun -np 8 cmuts --chunk-size 64 -o output.h5 -f ref.fasta input.bam\n\n# For memory-constrained systems\nmpirun -np 4 cmuts --low-mem --chunk-size 32 ...\n</code></pre>"},{"location":"installation/mpi-installation/#performance-optimization","title":"Performance Optimization","text":""},{"location":"installation/mpi-installation/#recommended-settings","title":"Recommended Settings","text":"<pre><code># Optimized MPI execution\nmpirun -np 8 \\\n    --map-by core \\\n    --bind-to core \\\n    cmuts -o output.h5 -f reference.fasta input.bam \\\n    --chunk-size 256 \\\n    --no-insertions \\\n    --filter-coverage\n</code></pre>"},{"location":"installation/mpi-installation/#io-optimization","title":"I/O Optimization","text":"<ul> <li>Use SSD storage for input and output files</li> <li>Place temporary files on local fast storage</li> <li>Avoid network filesystems for intensive I/O when possible</li> </ul>"},{"location":"installation/mpi-installation/#next-steps","title":"Next Steps","text":"<p>With MPI cmuts installed:</p> <ol> <li>Performance Testing - Benchmark your installation</li> <li>Advanced Usage - Explore parallel processing options</li> <li>Cluster Integration - Deploy on computing clusters</li> <li>Optimization Guide - Tune performance parameters</li> </ol>"},{"location":"installation/mpi-installation/#updating-mpi-installation","title":"Updating MPI Installation","text":"<pre><code>cd cmuts\ngit pull origin main\ngit submodule update --recursive\n\n# Clean build for MPI\nrm -rf build/ bin/\n./configure --mpi\n</code></pre>"},{"location":"installation/org-notes/","title":"Organization-Specific Notes","text":"<p>The following is an incomplete list of various locations where <code>cmuts</code> has been run, and the specific requirements for each one.</p>"},{"location":"installation/org-notes/#stanford-sherlock-cluster","title":"Stanford Sherlock Cluster","text":"<p>Both building and running will require the following, which covers all dependencies.</p> <pre><code>ml load hdf5/1.14.4\nml load biology samtools/1.16.1\nml load cmake/3.31.4\n</code></pre>"},{"location":"installation/org-notes/#hhmi-janelia-cluster","title":"HHMI Janelia Cluster","text":"<p>Running will require the following two commands.</p> <pre><code>ml load samtools\nLD_LIBRARY_PATH=/misc/local/samtools-1.22.1/lib:$LD_LIBRARY_PATH\n</code></pre> <p>In addition, building <code>cmuts</code> will require</p> <pre><code>ml load cmake/4.0.2\nexport PKG_CONFIG_PATH=/misc/local/samtools-1.22.1/lib/pkgconfig:$PKG_CONFIG_PATH\n</code></pre>"},{"location":"installation/requirements/","title":"Requirements","text":"<pre><code># Requirements\n\nThis page outlines the system requirements and dependencies needed to build and run cmuts.\n\n## System Requirements\n\n### Operating Systems\n\ncmuts is supported on:\n\n- **Linux** (Ubuntu 20.04+, CentOS 7+, etc.)\n- **macOS** (10.15+)\n- **Windows** (via WSL2 recommended)\n\n### Hardware Requirements\n\n=== \"Minimum\"\n    - **CPU**: 2 cores\n    - **RAM**: 4 GB\n    - **Storage**: 1 GB free space\n\n=== \"Recommended\"\n    - **CPU**: 8+ cores (for parallel processing)\n    - **RAM**: 16+ GB (for large datasets)\n    - **Storage**: 10+ GB free space\n    - **SSD**: For improved I/O performance\n\n## Core Dependencies\n\n### Required for Basic Installation\n\n| Dependency | Minimum Version | Purpose |\n|------------|----------------|---------|\n| **cmake** | 3.29+ | Build system |\n| **samtools** | 1.10+ | SAM/BAM/CRAM file handling |\n| **HTSlib** | 1.10+ | High-throughput sequencing data |\n| **HDF5** | 1.10+ | Output file format |\n| **autoconf** | 2.69+ | Building htscodecs dependency |\n\n### Additional for MPI Support\n\n| Dependency | Purpose |\n|------------|---------|\n| **OpenMPI** | Parallel processing |\n| **HDF5 with parallel support** | Parallel HDF5 I/O |\n\n## Installation Methods\n\n### Package Managers\n\n=== \"Homebrew (macOS/Linux)\"\n    ```bash\n    brew install cmake samtools hdf5 autoconf\n\n    # For MPI support\n    brew install hdf5-mpi open-mpi\n    ```\n\n=== \"Ubuntu/Debian\"\n    ```bash\n    sudo apt update\n    sudo apt install cmake samtools libhts-dev libhdf5-dev autoconf\n\n    # For MPI support\n    sudo apt install libhdf5-openmpi-dev openmpi-bin libopenmpi-dev\n    ```\n\n=== \"CentOS/RHEL\"\n    ```bash\n    sudo yum install cmake samtools htslib-devel hdf5-devel autoconf\n\n    # For MPI support  \n    sudo yum install hdf5-openmpi-devel openmpi-devel\n    ```\n\n### Stanford Sherlock Users\n\nIf you're running on Stanford's Sherlock cluster:\n\n```bash\nml load hdf5/1.14.4\nml load biology samtools/1.16.1  \nml load cmake/3.31.4\n\n# For MPI support\nml load openmpi/4.1.2\n</code></pre> <p>Module Availability</p> <p>Module versions may change. Use <code>ml avail</code> to see currently available versions.</p>"},{"location":"installation/requirements/#python-dependencies-for-cmuts-normalize","title":"Python Dependencies (for cmuts-normalize)","text":"<p>The normalization component requires:</p> <ul> <li>Python: 3.10 or higher</li> <li>Packages: Listed in <code>requirements.txt</code></li> </ul> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"installation/requirements/#environment-variables","title":"Environment Variables","text":""},{"location":"installation/requirements/#hdf5-configuration","title":"HDF5 Configuration","text":"<p>If cmake has trouble finding your HDF5 installation:</p> <pre><code>export HDF5_DIR=/path/to/hdf5/installation\n</code></pre>"},{"location":"installation/requirements/#for-custom-installations","title":"For Custom Installations","text":"<pre><code># Add to your shell profile (.bashrc, .zshrc, etc.)\nexport CMAKE_PREFIX_PATH=\"/usr/local:$CMAKE_PREFIX_PATH\"\nexport PKG_CONFIG_PATH=\"/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH\"\n</code></pre>"},{"location":"installation/requirements/#verification","title":"Verification","text":""},{"location":"installation/requirements/#check-dependencies","title":"Check Dependencies","text":"<p>Verify your installations:</p> <pre><code># Check versions\ncmake --version        # Should be 3.29+\nsamtools --version     # Should show version info\npkg-config --modversion hdf5    # Should show HDF5 version\n\n# Check MPI (if needed)\nmpirun --version       # Should show OpenMPI version\n</code></pre>"},{"location":"installation/requirements/#test-hdf5","title":"Test HDF5","text":"<pre><code># Test basic HDF5 functionality\nh5dump --version\n</code></pre>"},{"location":"installation/requirements/#common-issues","title":"Common Issues","text":"<p>HDF5 Detection Problems</p> <p>If cmake cannot find HDF5, try: </p><pre><code>export HDF5_DIR=$(brew --prefix hdf5)  # macOS with Homebrew\n# or\nexport HDF5_DIR=/usr/lib/x86_64-linux-gnu/hdf5/serial  # Ubuntu\n</code></pre><p></p> <p>Samtools Version</p> <p>Older versions of samtools may not support all CRAM features. We recommend version 1.15 or newer for best compatibility.</p> <p>MPI vs Single-threaded</p> <p>You can install and use the single-threaded version first, then add MPI support later if needed. The basic version is sufficient for most use cases.</p>"},{"location":"installation/requirements/#next-steps","title":"Next Steps","text":"<p>Once you have all dependencies installed:</p> <ol> <li>Basic Installation - Build the single-threaded version</li> <li>MPI Installation - Add parallel processing support</li> <li>Quick Start Guide - Begin using cmuts</li> </ol>"},{"location":"usage/cmuts/","title":"cmuts","text":""},{"location":"usage/cmuts/#cmuts","title":"cmuts","text":"<p><code>cmuts</code> is a program for counting mutations and computing reactivity profiles in MaP-seq experiments. It features fast, compiled C++ code with native multithreading support, streamed IO, and direct output to compressed HDF5 files.</p>"},{"location":"usage/cmuts/#basic-usage","title":"Basic Usage","text":""},{"location":"usage/cmuts/#modification-counting","title":"Modification Counting","text":"<p>To count modifications in a single aligned HTS file:</p> <pre><code>cmuts -o out.h5 -f seq.fasta sorted.bam\n</code></pre> <p>For the MPI-enabled version, use multiple threads:</p> <pre><code>mpirun -np 8 cmuts -o out.h5 -f seq.fasta sorted.bam\n</code></pre> <p>Multiple SAM/BAM/CRAM files can be processed simultaneously:</p> <pre><code>mpirun -np 8 cmuts -o out.h5 -f seq.fasta sorted1.bam sorted2.bam ...\n</code></pre>"},{"location":"usage/cmuts/#required-inputs","title":"Required Inputs","text":"<ol> <li>Reference sequences: A FASTA file specified with the <code>-f</code> option</li> <li>Aligned reads: One or more SAM/BAM/CRAM files</li> </ol> <p>The program will automatically create necessary index files (.bai or .crai) and a custom binary .binfa file from the FASTA file. If input files are not sorted, <code>samtools sort</code> will be called automatically.</p>"},{"location":"usage/cmuts/#output-format","title":"Output Format","text":"<p>The output HDF5 file contains one dataset per input file, named by the file path (without extension). Each dataset has shape <code>n \u00d7 l \u00d7 4 \u00d7 7</code> where:</p> <ul> <li><code>n</code> = number of sequences</li> <li><code>l</code> = maximum sequence length  </li> <li>Dimension 2 = original base (A, C, G, T)</li> <li>Dimension 3 = mutated base or inserted base</li> </ul>"},{"location":"usage/cmuts/#command-line-options","title":"Command Line Options","text":""},{"location":"usage/cmuts/#core-options","title":"Core Options","text":"<p><code>-o, --output</code> : Output HDF5 filename (required)</p> <p><code>-f, --fasta</code> : Reference FASTA file (required)</p>"},{"location":"usage/cmuts/#output-control","title":"Output Control","text":"<p><code>--overwrite</code> : Overwrite existing HDF5 file</p> <p><code>--compression</code> : HDF5 compression level (0-9, default: 3)</p>"},{"location":"usage/cmuts/#analysis-modes","title":"Analysis Modes","text":"<p><code>--tokenize</code> : Tokenize reference sequences and store in <code>sequence</code> dataset</p> <p><code>--joint</code> : Compute joint distribution of mutations over all position pairs</p> <p><code>--low-mem</code> : Record only modification locations and coverage (not type), reducing memory usage by 2x+</p>"},{"location":"usage/cmuts/#quality-filtering","title":"Quality Filtering","text":"<p><code>--min-mapq</code> : Mapping quality threshold (default: 10)</p> <p><code>--min-phred</code> : PHRED score threshold (default: 10)</p> <p><code>--quality-window</code> : Quality check window size around each base (default: 2)</p> <p><code>--min-length</code> : Minimum alignment length (default: 2)</p> <p><code>--max-length</code> : Maximum alignment length (default: 10,000)</p>"},{"location":"usage/cmuts/#modification-detection","title":"Modification Detection","text":"<p><code>--max-indel-length</code> : Maximum indel length to consider (default: 10)</p> <p><code>--collapse</code> : Collapse modifications within this distance in a read (default: 2)</p> <p><code>--no-mismatches</code> : Exclude mismatches from modification counts</p> <p><code>--no-insertions</code> : Exclude insertions from modification counts (recommended for MaP-seq)</p> <p><code>--no-deletions</code> : Exclude deletions from modification counts</p>"},{"location":"usage/cmuts/#deletion-handling","title":"Deletion Handling","text":"<p><code>--uniform-spread</code> : Uniformly spread ambiguous deletions</p> <p><code>--mutation-spread</code> : Spread ambiguous deletions according to existing mutation profile</p> <p><code>--disable-ambiguous</code> : Use alignment-provided deletions only</p> <p><code>--contiguous-ambiguous</code> : Allow only contiguous regions as ambiguous deletions</p>"},{"location":"usage/cmuts/#sampling-and-coverage","title":"Sampling and Coverage","text":"<p><code>--subsample</code> : Random read acceptance probability (default: 1.0)</p> <p><code>--filter-coverage</code> : Apply modification filters to matches (recommended for MaP-seq)</p>"},{"location":"usage/cmuts/#performance","title":"Performance","text":"<p><code>--chunk-size</code> : Internal buffer size per thread in references (default: 128)</p> <p><code>--print-every</code> : Progress update frequency in reads processed (default: 1,000)</p>"},{"location":"usage/cmuts/#special-use-cases","title":"Special Use Cases","text":""},{"location":"usage/cmuts/#tokenization-only","title":"Tokenization Only","text":"<p>Generate tokenized sequences without processing alignments:</p> <pre><code>cmuts --tokenize -f seq.fasta -o out.h5\n</code></pre>"},{"location":"usage/cmuts/#joint-modification-analysis","title":"Joint Modification Analysis","text":"<p>Compute joint modification distributions:</p> <pre><code>cmuts --joint -o joint.h5 -f seq.fasta sorted.bam\n</code></pre> <p>Output shape: <code>n \u00d7 l \u00d7 l \u00d7 2 \u00d7 2</code> where the final dimensions indicate modification presence (1) or absence (0) at each position pair.</p>"},{"location":"usage/cmuts/#memory-efficient-analysis","title":"Memory-Efficient Analysis","text":"<p>For large datasets, use low-memory mode:</p> <pre><code>cmuts --low-mem -o out.h5 -f seq.fasta sorted.bam\n</code></pre>"},{"location":"usage/cmuts/#recommended-map-seq-settings","title":"Recommended MaP-seq Settings","text":"<p>For standard MaP-seq analysis, use:</p> <pre><code>cmuts --no-insertions --filter-coverage -o out.h5 -f seq.fasta sorted.bam\n</code></pre> <p>These flags: - Exclude insertions which are not relevant for chemical modification detection - Apply consistent quality filters to both modifications and coverage calculations</p>"}]}