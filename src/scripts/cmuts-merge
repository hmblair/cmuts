#!/usr/bin/env python3

import h5py
import dask.array as da
import os
import argparse
import numpy as np

MERGED="merged"

parser = argparse.ArgumentParser()
parser.add_argument(
    '--files',
    nargs="+",
    help='The HDF5 files containing the data to merge.',
    required=True,
)
parser.add_argument(
    '--datasets',
    nargs="+",
    help='The names of the datasets to merge, in correspondance with the provided files.',
    required=True,
)
parser.add_argument(
    '-o', '--output',
    help='The output HDF5 file to write to.',
    required=True,
)
parser.add_argument(
    '--group',
    help='The group in the output file to place the merged counts.',
    default="",
)
parser.add_argument(
    '--overwrite',
    help='Overwrite an existing HDF5 file (the whole file, not just the group).',
    action='store_true',
)


def _remove_if_exists(
    path: str,
    overwrite: bool = False
) -> None:
    if os.path.exists(path):
        if overwrite:
            os.remove(path)


def _merge(
    files: list[h5py.File],
    groups: list[str],
) -> da.array:

    if len(files) != len(groups):
        raise ValueError(
            f"Error: the number of files ({len(files)}) does not match the "
            f"number of groups ({len(groups)})."
        )

    ix = 0
    arr = 0
    for file, group in zip(files, groups):
        try:
            arr += da.from_array(file[group], chunks='auto')
            ix += 1
        except Exception as e:
            print(f"Error with the dataset {group}:")
            print(e)
            continue

    if not ix:
        raise RuntimeError("No datasets were successfully merged.")

    return arr


if __name__ == '__main__':

    args = parser.parse_args()
    _remove_if_exists(args.output, args.overwrite)

    files = [h5py.File(name, 'r') for name in args.files]
    arr = _merge(files, args.datasets)

    data = {
        args.group + f'/{MERGED}': arr,
    }
    da.to_hdf5(args.output, data)
