#!/usr/bin/env python3

import h5py
import dask.array as da
import os
import argparse
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
from enum import Enum


class NormMethod(Enum):
    RAW = 0
    UBR = 1
    OUTLIER = 2
    WINSORIZING = 3
    BOXPLOT = 4


BOLD = '\033[1m'
RESET = '\033[0m'

with open(f"{os.path.dirname(os.path.abspath(__file__))}/VERSION", "r") as f:
    VERSION = f.read().strip()

NAME = 'cmuts-normalize'
PBAR_WIDTH = 20
FIGURES = "figures"

REACTIVITY_DS = 'reactivity'
READS_DS = 'reads'
ERROR_DS = "error"
SNR_DS = "SNR"
NORM_DS = "norm"
ROI_DS = "ROI"
HEATMAP_DS = "heatmap"
SEQUENCE_DS = 'sequence'

IX_DEL = 4
IX_INS = 5
IX_TERM = 6

parser = argparse.ArgumentParser()
parser.add_argument(
    'file',
    help='The HDF5 file containing the input data.',
)
parser.add_argument(
    '--mod',
    nargs="+",
    help='The names of the datasets containing the mutation counts of the modified sequences.',
    required=True,
)
parser.add_argument(
    '--nomod',
    nargs="+",
    help='The names of the datasets containing the mutation counts of the non-modified sequences.',
)
parser.add_argument(
    '--group',
    help='The group in the output file to place the reads and reactivities.',
    default="",
)
parser.add_argument(
    '-o', '--out',
    help='The output HDF5 file to write to.',
    default='reactivity.h5'
)
parser.add_argument(
    '--overwrite',
    help='Overwrite an existing HDF5 file (the whole file, not just the group).',
    action='store_true',
)
parser.add_argument(
    '--clip-low',
    help='Clip negative reactivity values.',
    action='store_true',
)
parser.add_argument(
    '--clip-high',
    help='Clip reactivity values above 1.',
    action='store_true',
)
parser.add_argument(
    '--5p-primer-length',
    help='The length of the 5\' primer, which will be zeroed out.',
    type=int,
    default=0,
)
parser.add_argument(
    '--3p-primer-length',
    help='The length of the 3\' primer, which will be zeroed out.',
    type=int,
    default=0,
)
parser.add_argument(
    '--raw',
    help='Do not normalize the reactivity values.',
    action='store_true',
)
parser.add_argument(
    '--norm-cutoff',
    help='References with at least this many reads are used for normalization.',
    type=int,
    default=500,
)
parser.add_argument(
    '--norm-percentile',
    help='The reactivity percentile to use for normalization.',
    type=int,
    default=90,
)


def _title(program: str, version: str, name: str) -> str:
    return f"""        {program} version {version}
      ───────────────────────────────────
        {BOLD}Statistics for {name}:{RESET}"""


def _remove_if_exists(
    path: str,
    overwrite: bool = False
) -> None:
    if os.path.exists(path):
        if overwrite:
            os.remove(path)


def _reactivity(modifications: da.Array, coverage: da.Array) -> da.Array:

    return da.divide(
        modifications,
        coverage,
        where=(coverage > 0),
        out=da.zeros_like(modifications),
    )


def _error(reactivity: da.Array, coverage: da.Array) -> da.Array:

    return da.divide(
        da.sqrt(reactivity * (1 - reactivity)),
        da.sqrt(coverage),
        where=(coverage > 0),
        out=da.ones_like(reactivity),
    )


def _snr(reactivity: da.Array, error: da.Array) -> da.Array:

    return np.divide(
        reactivity,
        error,
        where=(error > 0),
        out=np.zeros_like(reactivity),
    ).mean(-1)


def _print_stats(
    reactivity: np.ndarray,
    reads: np.ndarray,
    snr: np.ndarray,
    norm: np.ndarray,
) -> None:

    nseqs = reads.shape[0]

    tr = np.sum(reads)
    mr = np.mean(reads)
    medr = np.median(reads)

    msnr = np.mean(snr)
    medsnr = np.median(snr)

    mrr = np.mean(reactivity * norm)
    fsnr = np.mean(snr >= 1)

    dr_f = (reads == 0).sum() / reads.shape[0]

    with np.errstate(divide='ignore', invalid='ignore'):
        med2m = mr / medr

    print(f"        References:       {nseqs:,}")
    print(f"        Total reads:      {int(tr):,}")
    print(f"        Mean reads:       {mr:.2f}")
    print(f"        Mean SNR:         {msnr:.2f}")
    print(f"        Mean reactivity:  {mrr:.3f}")
    print(f"        Median reads:     {int(medr):,}")
    print(f"        Median SNR:       {medsnr:.2f}")
    print(f"        Mean-to-Median:   {med2m:.2f}")
    print(f"        Usable SNR:       {fsnr:.2f}")
    print(f"        Dropout Fraction: {dr_f:.2f}")
    print()


def _process(file: h5py.File, groups: list[str]) -> tuple[np.ndarray, ...]:

    if not groups:
        raise ValueError("At least one group must be specified.")

    # Lazily load the HDF5 files into dask arrays

    arr = 0
    ix = 0

    for group in groups:
        try:
            arr += da.from_array(file[group], chunks='auto')
            ix += 1
        except Exception as e:
            print(f"Error loading the dataset {group}:")
            raise e

    if not ix:
        raise RuntimeError("No datasets were successfully loaded.")

    # Compute the modification heatmap

    heatmap = arr.mean((0, 1))
    heatmap[..., :IX_TERM] = heatmap[..., :IX_TERM] / heatmap[..., :IX_TERM].sum()
    heatmap[..., IX_TERM] = heatmap[..., IX_TERM] / heatmap[..., IX_TERM].sum()

    # Compute the coverage as the sum of all mutated, non-mutated, and
    # deleted bases. Store the mean coverage as a function of position
    # for later.

    coverage = da.sum(arr[..., :IX_INS], axis=(2, 3))
    mc = da.mean(coverage, axis=0)

    # Get termination events

    term = da.sum(arr[..., IX_TERM], axis=2)
    term = term / term.sum()

    # Compute the trace to get the non-modified rates only

    trace = da.trace(arr, axis1=2, axis2=3)

    # Compute the insertions

    ins = da.sum(arr[..., IX_INS], axis=-1)

    # Subtract the trace to get the pure modifications

    modifications = coverage + ins - trace

    # Divide by the coverage to get the un-normalised reactivity

    reactivity = _reactivity(modifications, coverage)

    # SEM of a Bernoulli random variable

    err = _error(reactivity, coverage)

    # Blank out the ends of the sequence

    reactivity[:, :BLANK_OUT5] = 0
    reactivity[:, BLANK_OUT3:] = 0
    err[:, :BLANK_OUT5] = 0
    err[:, BLANK_OUT3:] = 0

    # Get the read counts and compute all values

    reads = da.max(coverage, axis=(-1,))

    # Normalize the mean coverage based on the total reads

    mc /= reads.sum()

    # Compute all lazy results

    return da.compute(reactivity, reads, err, heatmap, mc, term)


def _get_norm_raw(reactivity: np.ndarray) -> np.ndarray:
    """
    No normalization.
    """

    return np.ones(1, dtype=reactivity.dtype)


def _get_norm_2_8(reactivity: np.ndarray) -> np.ndarray:
    """
    2-8% Normalization: From top 10%, ignore top 2% and divide by average of
    remaining 8%
    """

    p90 = np.percentile(reactivity, 90)
    p98 = np.percentile(reactivity, 98)

    values = reactivity[(reactivity >= p90) & (reactivity < p98)]
    return np.mean(values)


def _get_norm_winsorizing(reactivity: np.ndarray) -> np.ndarray:
    """
    90% Winsorizing: Clip values to 5th-95th percentile range, then divide by
    95th percentile
    """

    p5 = np.percentile(reactivity, 5)
    p95 = np.percentile(reactivity, 95)

    # TODO: fix

    winsorized = np.clip(reactivity, p5, p95)
    return winsorized / p95


def _get_norm_boxplot(reactivity: np.ndarray) -> np.ndarray:
    """
    Box-plot Normalization: Remove outliers beyond 1.5x IQR above Q3,
    then divide by average of next 10% of remaining values
    """

    q1 = np.percentile(reactivity, 25)
    q3 = np.percentile(reactivity, 75)
    iqr = q3 - q1

    threshold = q3 + 1.5 * iqr
    non_outliers = reactivity[reactivity <= threshold]
    p90_non_outliers = np.percentile(non_outliers, 90)

    top_10_percent = non_outliers[non_outliers >= p90_non_outliers]
    return np.mean(top_10_percent)


def _get_norm_ubr(
    reactivity: np.ndarray,
    reads: np.ndarray,
    cutoff: int,
    percentile: int,
) -> np.ndarray:

    high_reactivity = reactivity[reads > cutoff]
    return np.percentile(high_reactivity[:, UNBLANKED].flatten(), percentile)


def _get_norm(
    reactivity: np.ndarray,
    reads: np.ndarray,
    cutoff: int,
    percentile: int,
    method: NormMethod = NormMethod.RAW,
) -> tuple[np.ndarray, ...]:

    if method == NormMethod.RAW:
        return _get_norm_raw(reactivity)
    if method == NormMethod.UBR:
        return _get_norm_ubr(reactivity, reads, cutoff, percentile)
    if method == NormMethod.OUTLIER:
        return _get_norm_2_8(reactivity)
    if method == NormMethod.WINSORIZING:
        return _get_norm_winsorizing(reactivity)
    if method == NormMethod.BOXPLOT:
        return _get_norm_boxplot(reactivity)


def _get_sequences(file: h5py.File) -> da.Array:
    # Get the tokenized sequences if they exist
    if SEQUENCE_DS in file:
        return da.from_array(file[SEQUENCE_DS], chunks='auto')

    return None


def _plot_heatmap(heatmap: da.Array, name: str) -> None:

    prefix = f"{name}-" if name else ""

    im = plt.imshow(heatmap, cmap="RdPu", norm=LogNorm(vmin=1E-4, vmax=1E0))
    plt.colorbar(im, label="Occurrence Probability")

    plt.title(f"Modification Heatmap for {name}", fontsize=15)
    plt.xticks(range(7), ["A", "C", "G", "U", "del", "ins", "term"], fontsize=12)
    plt.yticks(range(4), ["A", "C", "G", "U"], fontsize=12)

    plt.savefig(f"{FIGURES}/{prefix}heatmap.png", dpi=300, bbox_inches="tight")
    plt.close()


def _plot_read_hist(reads: np.ndarray, name: str) -> None:

    prefix = f"{name}-" if name else ""

    # Compute log-read depths

    with np.errstate(divide='ignore'):
        lr = np.where(reads == 0, -1, np.log10(reads))

    plt.grid(axis="y", alpha=0.5)
    plt.hist(lr, bins=100, color=plt.cm.RdPu(0.6))
    plt.title(f"Read distribution for {name}", fontsize=15)
    plt.xlabel("log10 Read Depth", fontsize=12)
    plt.ylabel("Count", fontsize=12)

    plt.savefig(f"{FIGURES}/{prefix}reads-hist.png", dpi=300, bbox_inches="tight")
    plt.close()


def _plot_termination(term: np.ndarray, name: str) -> None:

    prefix = f"{name}-" if name else ""

    term = np.mean(term, axis=0)

    plt.grid(axis="y", alpha=0.5)
    plt.fill_between(range(len(term)), term, alpha=0.5, color=plt.cm.RdPu(0.3))
    plt.plot(term, color=plt.cm.RdPu(0.8), linewidth=1)

    plt.xlabel("Residue", fontsize=13)
    plt.ylabel("Termination density", fontsize=13)
    plt.title(f"Termination by position for {name}", fontsize=14)
    plt.savefig(f"{FIGURES}/{prefix}termination.png", dpi=300, bbox_inches="tight")
    plt.close()


def _plot_examples(reactivity: np.ndarray, name: str, num: int = 500) -> None:

    prefix = f"{name}-" if name else ""

    if reactivity.shape[0] == 1:
        reactivity = reactivity[0]

        plt.grid(axis="y", alpha=0.5)
        plt.fill_between(range(len(reactivity)), reactivity, alpha=0.5, color=plt.cm.RdPu(0.3))
        plt.plot(reactivity, color=plt.cm.RdPu(0.8), linewidth=1)
        plt.xlabel("Residue", fontsize=12)
        plt.ylabel("Reactivity", fontsize=12)
        plt.title(f"Profile of {name}", fontsize=14)
        plt.savefig(f"{FIGURES}/{prefix}profile.png", dpi=300, bbox_inches="tight")
        plt.close()

    else:
        plt.imshow(reactivity[:num], cmap="RdPu")
        plt.xlabel("Residue", fontsize=12)
        plt.ylabel("Sequence Index", fontsize=12)
        plt.title(f"Profile heatmap of {name}", fontsize=14)
        plt.savefig(f"{FIGURES}/{prefix}examples.png", dpi=300, bbox_inches="tight")
        plt.close()


def _plot_coverage(coverage: np.ndarray, name: str) -> None:

    prefix = f"{name}-" if name else ""

    plt.fill_between(range(len(coverage)), coverage, alpha=0.5, color=plt.cm.RdPu(0.3))
    plt.plot(coverage, color=plt.cm.RdPu(0.8))
    plt.xlabel("Residue", fontsize=13)
    plt.ylabel("Fraction of reads", fontsize=13)
    plt.title(f"Coverage by position for {name}", fontsize=14)
    plt.savefig(f"{FIGURES}/{prefix}coverage.png", dpi=300, bbox_inches="tight")
    plt.close()


if __name__ == '__main__':

    args = parser.parse_args()
    print(_title(NAME, VERSION, args.group))

    _remove_if_exists(args.out, args.overwrite)

    # Treat an empty nomod dataset as if it were not passed

    if not args.nomod:
        args.nomod = None

    with h5py.File(args.file, 'r') as f:

        BLANK_OUT5 = getattr(args, "5p_primer_length")
        BLANK_OUT3 = f[args.mod[0]].shape[1] - getattr(args, "3p_primer_length")
        UNBLANKED = slice(BLANK_OUT5, BLANK_OUT3)

        mod_reactivity, reads, err, heatmap, mc, term = _process(f, args.mod)

        if args.nomod is not None:
            nomod_reactivity, nomod_reads, no_mod_err, no_mod_heatmap, _, _ = _process(f, args.nomod)
            reads += nomod_reads
            err = np.sqrt(err ** 2 + no_mod_err ** 2)

        # Background subtract

        if args.nomod is not None:
            reactivity = mod_reactivity - nomod_reactivity
        else:
            reactivity = mod_reactivity

        # Normalize the reactivity and its error
        # SNR is unchanged

        norm = _get_norm(
            reactivity,
            reads,
            args.norm_cutoff,
            args.norm_percentile,
        )
        err /= norm
        reactivity /= norm

        snr = _snr(reactivity, err)

        # Clip the reactivity if requested

        if args.clip_low:
            reactivity = da.clip(reactivity, 0, None)
        if args.clip_high:
            reactivity = da.clip(reactivity, None, 1)

        # Find the region of interest

        roi = np.array([BLANK_OUT5, reactivity.shape[1] + BLANK_OUT3])

        # Save to file

        data = {
            args.group + '/' + REACTIVITY_DS: da.from_array(reactivity),
            args.group + '/' + READS_DS: da.from_array(reads),
            args.group + '/' + NORM_DS: da.from_array(norm),
            args.group + '/' + ROI_DS: da.from_array(roi),
            args.group + '/' + ERROR_DS: da.from_array(err),
            args.group + '/' + SNR_DS: da.from_array(snr),
            args.group + '/' + HEATMAP_DS: da.from_array(heatmap),
        }

        da.to_hdf5(args.out, data)

        # Print stats

        _print_stats(reactivity, reads, snr, norm)

        # Plot figures

        os.makedirs(FIGURES, exist_ok=True)
        _plot_heatmap(heatmap, args.group)
        _plot_read_hist(reads, args.group)
        _plot_examples(reactivity, args.group)
        _plot_termination(term, args.group)
        _plot_coverage(mc, args.group)

        # Get the embedded sequences

        sequences = _get_sequences(f)

        if sequences is not None:

            aux_data = {
                SEQUENCE_DS: sequences,
            }
            da.to_hdf5(args.out, aux_data)
